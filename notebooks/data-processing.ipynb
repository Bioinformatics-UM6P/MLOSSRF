{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10621774,"sourceType":"datasetVersion","datasetId":6576498},{"sourceId":203061814,"sourceType":"kernelVersion"},{"sourceId":209354619,"sourceType":"kernelVersion"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport gc\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom scipy.stats.mstats import winsorize\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import stats\nimport tensorflow as tf\n\ngc.enable()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-20T13:14:59.320446Z","iopub.execute_input":"2025-04-20T13:14:59.321042Z","execution_failed":"2025-04-20T13:14:59.308Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed) \nrandom.seed(seed) \ntf.random.set_seed(seed) ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/al-moutmir/data.csv')","metadata":{"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Filter Rows & Drop Columns","metadata":{}},{"cell_type":"code","source":"# Drop rows where 'variety' equals \"Irrigated\"\ndata = data[data['water_regime'] != \"Irrigated\"]\n\n# Drop rows where 'crop' equals \"Oats\"\ndata = data[data['crop'] != 'Oats']\n# data = data[data['crop'] != 'Baley']\n\n# Drop specified columns\ndata.drop(['variety', 'water_regime', 'weather_date_range', 'growth_season_year'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter out future-collected columns\nfuture_collected_columns = [\n    'ID', 'harvesting_date', 'sowing_date', 'sowing_rate_kg_ha', 'height_at_anthesis_cm',\n    'plant_density_tillering', 'tillers_at_booting', 'ears_per_plant', 'fresh_biomass_kg_ha',\n    'harvest_index', 'thousand_seed_weight_g', 'topdress_calcium_cao', 'topdress_potassium_k2o',\n    'topdress_phosphorus_p2o5', 'topdress_magnesium_mgo', 'topdress_sulfur_so3', 'topdress_nitrogen',\n    'topdress_applications'\n]\n\ndata.drop(future_collected_columns, axis=1, inplace=True, errors='ignore')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Clean Numeric and Non–Numeric Columns","metadata":{}},{"cell_type":"code","source":"region_mapping = {\n    'Beni mellal - Khénifra ': 'Beni Mellal-Khénifra',\n    'Oriental ': 'Oriental',\n    'Fès - Meknès': 'Fès-Meknès',\n    'Marrakach-safi': 'Marrakech-Safi',\n    'Rabat Sale Kénita': 'Rabat-Salé-Kénitra',\n    'Tanger-Tétouan-Al Hoceïma': 'Tanger-Tétouan-Al Hoceima',\n    'Casablanca-Settat': 'Casablanca-Settat',\n    'Draa-Tafilalet': 'Drâa-Tafilalet'\n}\n\n# Clean and map region names\ndata['region'] = data['region'].map(region_mapping)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_province_names(data, column_name):\n    # Standardize names: remove extra spaces, handle casing\n    data[column_name] = data[column_name].str.strip().str.title()\n\n    # Define mappings for specific corrections\n    province_corrections = {\n        \"El jadida\": \"El Jadida\",\n        \"Fés\": \"Fès\",\n        \"Khémisset\": \"Khemisset\",\n        \"Khénifra\": \"Khenifra\",\n        \"Séfrou\": \"Sefrou\",\n        \"Sidi bennour\": \"Sidi Bennour\",\n        \"Azilal \": \"Azilal\",\n        \"Fkih ben salah\": \"Fkih Ben Salah\",\n        \"OUEZZANE\": \"Ouezzane\",\n        \"Sidi slimane\": \"Sidi Slimane\",\n        \"TANGER ASSILAH\": \"Tanger-Assilah\",\n        \"ASSILAH\": \"Assilah\",\n        \"El Youssoufia\": \"Youssoufia\"\n    }\n\n    # Apply corrections\n    data[column_name] = data[column_name].replace(province_corrections)\n\n    return data\n\n# Apply the function to the 'province' column\ndata = clean_province_names(data, 'province')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a function to clean the 'previous_crop' column\ndef clean_previous_crop(data, column_name):\n    # Standardize the column to lowercase\n    data[column_name] = data[column_name].str.lower().str.strip()\n\n    # Define mappings for grouping similar categories\n    crop_mapping = {\n        \"soft wheat\": \"Soft Wheat\",\n        \"fallow\": \"Fallow\",\n        \"chickpea\": \"Chickpea\",\n        \"sugar beet\": \"Sugar Beet\",\n        \"bean\": \"Bean\",\n        \"beans\": \"Bean\",\n        \"faba bean\": \"Faba Bean\",\n        \"dry beans\": \"Dry Bean\",\n        \"durum wheat\": \"Durum Wheat\",\n        \"lens\": \"Lens\",\n        \"barley\": \"Barley\",\n        \"oats\": \"Oats\",\n        \"onion\": \"Onion\",\n        \"potato\": \"Potato\",\n        \"tomato (open field)\": \"Tomato\",\n        \"orobe\": \"Orobe\",\n        \"melon\": \"Melon\",\n        \"alfalfa\": \"Alfalfa\",\n        \"fennel flower\": \"Fennel Flower\",\n        \"triticale\": \"Triticale\",\n        \"watermelon\": \"Watermelon\",\n        \"rapeseed\": \"Rapeseed\",\n        \"sesame\": \"Sesame\",\n        \"other veg\": \"Other Vegetables\",\n        \"pea\": \"Pea\",\n        \"sugar cane\": \"Sugar Cane\",\n        \"niora\": \"Niora\",\n        \"parsley\": \"Parsley\",\n        \"cress\": \"Cress\",\n        \"fodder crop\": \"Fodder Crop\",\n        \"cordiander\": \"Coriander\",\n        \"carrot\": \"Carrot\",\n        \"cabbage\": \"Cabbage\"\n    }\n\n    # Map the cleaned values using the defined mapping\n    data[column_name] = data[column_name].map(crop_mapping).fillna(data[column_name])\n\n    # Standardize final output to title case for uniformity\n    data[column_name] = data[column_name].str.title()\n\n    return data\n\n# Apply the cleaning function to the 'previous_crop' column\ndata = clean_previous_crop(data, 'previous_crop')\ndata['previous_crop'].fillna('Other Vegetables', inplace=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clean the 'crop' column\ndata['crop'] = data['crop'].replace({\n    'S. wheat': 'Soft Wheat',\n    'D. Wheat': 'Durum Wheat',\n    'Baley': 'Barley'\n})","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Clean Numeric Columns","metadata":{}},{"cell_type":"code","source":"# Define a function to clean numeric columns\ndef clean_numeric_columns(df, exclude_substrings):\n    # Automatically detect numeric columns\n    numeric_columns = [col for col in df.select_dtypes(include=['object', 'float', 'int']).columns]\n\n    # Exclude columns containing any of the specified substrings\n    columns_to_clean = [\n        col for col in numeric_columns \n        if not any(substring in col for substring in exclude_substrings)\n    ]\n\n    # Replace specific unwanted strings and clean the data\n    df[columns_to_clean] = df[columns_to_clean].replace([' -   ', ' -     ', ' _ '], '')\n\n    # Remove commas, strip whitespace, and convert to numeric\n    for col in columns_to_clean:\n        df[col] = df[col].astype(str).str.replace(',', '', regex=False).str.strip()\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n\n    return df\n\n# Exclude substrings\nexclude_substrings = [\n    \"growth_season\", \"province\", \"region\", \"crop\", \"sub_program\"\n]\n\n# Example usage with your DataFrame 'data'\ndata = clean_numeric_columns(data, exclude_substrings)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Label Encoding","metadata":{}},{"cell_type":"code","source":"# Columns to label encode\nlabel_encode_columns = ['growth_season', 'region', 'province', 'sub_program',\n                        'crop', 'previous_crop'] #location_id\n\n# Initialize LabelEncoders for each column\nlabel_encoders = {col: LabelEncoder() for col in label_encode_columns}\n\n# Apply LabelEncoder to each column\nfor col in label_encode_columns:\n    data[col] = label_encoders[col].fit_transform(data[col])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the label encoding mappings for each column\nfor col, encoder in label_encoders.items():\n    print(f\"Label encoding for '{col}':\")\n    mapping = {original: encoded for encoded, original in enumerate(encoder.classes_)}\n    print(mapping)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Drop Missing Values","metadata":{}},{"cell_type":"code","source":"# List of substrings to exclude\nexclude_substrings = None\n\n# Filter columns to exclude those containing specified substrings\ncolumns_to_exclude = [col for col in data.columns if any(substring in col for substring in exclude_substrings)]\nfiltered_df = data.drop(columns=columns_to_exclude)\n\n# Calculate and sort the percentage of missing values for the remaining columns\nmissing_pct = filtered_df.isnull().mean() * 100\nmissing_pct_sorted = missing_pct.sort_values(ascending=False)\n\n# Print the sorted percentages of missing values\nprint(\"Percentage of missing values per column (sorted, filtered):\")\nmissing_pct_sorted","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dropping columns with more than 30% missing values\n# Define a threshold for dropping columns (e.g., 30% missing values)\nthreshold = 0.3\n\n# List columns to be dropped based on missing percentage threshold\ndropped_columns = []\n\nfor col in data.columns:\n    missing_percentage = data[col].isnull().sum() / len(data)\n    \n    # Check if column has more than the threshold of missing values\n    if missing_percentage > threshold:\n       dropped_columns.append(col)\n\n# Drop columns that meet the threshold and are not deemed essential\ndata.drop(dropped_columns, axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.310Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Winsorization","metadata":{}},{"cell_type":"code","source":"# Columns to Winsorize\ncolumns_to_winsorize = [\n    'soil_ph', 'organic_matter_percent', 'phosphorus_ppm', 'potassium_ppm',\n    'electrical_conductivity', 'npk_nitrogen', 'npk_phosphorus_p2o5',\n    'npk_potassium_k2o', 'npk_magnesium_mgo', 'npk_calcium_cao',\n    'grain_yield_kg'\n]\n\n# Dictionary to store Winsorization limits\nlimits_dict = {}\n\n# Winsorize each specified column and record limits\nfor column in columns_to_winsorize:\n    if column in data.columns:\n        # Calculate the proportion of data trimmed on both ends\n        q1 = data[column].quantile(0.15)\n        q9 = data[column].quantile(0.85)\n        lower_limit = (data[column] < q1).mean()\n        upper_limit = (data[column] > q9).mean()\n        limits_dict[column] = (lower_limit, upper_limit)\n        \n        # Apply Winsorization\n        data[column] = winsorize(data[column], limits=(lower_limit, upper_limit))\n\nlimits_dict","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.310Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Impute Missing Values","metadata":{}},{"cell_type":"code","source":"# List of low-missingness features\nlow_missing_features = [\n    'npk_magnesium_mgo', 'npk_calcium_cao', 'soil_ph',\n    'organic_matter_percent', 'phosphorus_ppm', 'potassium_ppm',\n    'npk_potassium_k2o', 'npk_phosphorus_p2o5', 'npk_nitrogen',\n    'electrical_conductivity'\n]\n\n# Define group levels for median imputation (from most granular to least granular)\ngroup_levels = [\n    ['longitude', 'latitude', 'crop', 'previous_crop'],\n    ['longitude', 'latitude', 'crop'],\n    ['longitude', 'latitude'],\n    ['province', 'crop', 'previous_crop'],\n    ['province', 'crop']\n]\n\n# Function to perform grouped median imputation\ndef grouped_median_imputation(df, columns, groupings):\n    \"\"\"\n    Perform grouped median imputation on specified columns.\n\n    Parameters:\n        df (pd.DataFrame): The DataFrame to modify.\n        columns (list): List of columns to impute.\n        groupings (list): List of grouping combinations (list of lists).\n    \"\"\"\n    for groups in groupings:\n        for col in columns:\n            df[col] = df[col].fillna(df.groupby(groups)[col].transform('median'))\n    return df\n\n# Perform grouped median imputation\ndata = grouped_median_imputation(data, low_missing_features, group_levels)\n\n# Fallback: Global median imputation for any remaining missing values\nfor col in low_missing_features:\n    data[col].fillna(data[col].median(), inplace=True)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndata['electrical_conductivity_encoded'] = label_encoder.fit_transform(data['electrical_conductivity'])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.310Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Remove Outliers","metadata":{}},{"cell_type":"code","source":"# List of crop types\ncrop_types = data['crop'].unique()\n\n# Create a copy of the original dataset to avoid overwriting it\ndata_cleaned = data.copy()\n\n# Loop over each crop type and remove outliers based on Z-score for each crop type individually\nfor crop in crop_types:\n    # Filter the data for the current crop\n    crop_data = data_cleaned[data_cleaned['crop'] == crop]\n    \n    # Calculate Z-scores only for the target column (grain_yield_kg) for this crop\n    if len(crop_data) > 0:  # Ensure there are rows to avoid errors\n        z_scores = np.abs(stats.zscore(crop_data['grain_yield_kg']))\n        \n        # Define outliers based on Z-score threshold\n        # Z > 2.0 (95.4% of data falls within this range)\n        outliers = z_scores > 2.0\n        \n        # Remove outliers for this crop type\n        data = data_cleaned[~((data_cleaned['crop'] == crop) & outliers)]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T13:14:59.310Z"}},"outputs":[],"execution_count":null}]}