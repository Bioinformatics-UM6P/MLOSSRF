{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":224869804,"sourceType":"kernelVersion"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport gc\nimport math\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy import stats\nfrom scipy.spatial.distance import cosine, mahalanobis\nfrom scipy.stats import ks_2samp, skew, kurtosis, entropy, f_oneway, norm\nfrom sklearn.decomposition import PCA\nfrom sklearn.base import clone\nfrom sklearn.model_selection import train_test_split, GroupShuffleSplit\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\nfrom sklearn.model_selection import \n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.svm import SVR\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Multiply, Add, BatchNormalization, LayerNormalization, MultiHeadAttention, Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.utils import plot_model\n\nimport shap\nfrom sklearn.inspection import permutation_importance\n\nos.makedirs(\"models\", exist_ok=True)\nos.makedirs(\"architectures\", exist_ok=True)\nos.makedirs(\"results\", exist_ok=True)\nos.makedirs(\"feature_analysis\", exist_ok=True)\nos.makedirs(\"optimization\", exist_ok=True)\n\ngc.enable()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-20T13:37:21.463139Z","iopub.status.idle":"2025-04-20T13:37:21.463451Z","shell.execute_reply.started":"2025-04-20T13:37:21.463270Z","shell.execute_reply":"2025-04-20T13:37:21.463281Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ntf.random.set_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.464822Z","iopub.status.idle":"2025-04-20T13:37:21.465113Z","shell.execute_reply.started":"2025-04-20T13:37:21.464966Z","shell.execute_reply":"2025-04-20T13:37:21.464978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/al-moutmir/data.csv')","metadata":{"execution":{"iopub.status.busy":"2025-04-20T13:37:21.466506Z","iopub.status.idle":"2025-04-20T13:37:21.466862Z","shell.execute_reply.started":"2025-04-20T13:37:21.466691Z","shell.execute_reply":"2025-04-20T13:37:21.466704Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sampling Methods","metadata":{}},{"cell_type":"markdown","source":"## Train-Test Split","metadata":{}},{"cell_type":"code","source":"# Define feature matrix (X) and target variable (y)\nX = data.drop(columns=['grain_yield_kg', 'yield_quartile'])\ny = data['grain_yield_kg']\n\n# Random and Temporal Splits\nX_train_rand, X_test_rand, y_train_rand, y_test_rand = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=42,\n)\n\ntrain_data = data[data['growth_season'] != data['growth_season'].max()]\ntest_data = data[data['growth_season'] == data['growth_season'].max()]\n\nX_train_temp = train_data.drop(columns=['grain_yield_kg', 'yield_quartile'])\ny_train_temp = train_data['grain_yield_kg']\nX_test_temp = test_data.drop(columns=['grain_yield_kg', 'yield_quartile'])\ny_test_temp = test_data['grain_yield_kg']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.468704Z","iopub.status.idle":"2025-04-20T13:37:21.468967Z","shell.execute_reply.started":"2025-04-20T13:37:21.468856Z","shell.execute_reply":"2025-04-20T13:37:21.468868Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Downsampling","metadata":{}},{"cell_type":"code","source":"# KS and Wasserstein before filtering\nks_stat, ks_p = ks_2samp(y_train_temp, y_test_temp)\nw_dist = wasserstein_distance(y_train_temp, y_test_temp)\nprint(f\"Before filtering: KS={ks_stat:.3f}, p={ks_p:.3e}, Wasserstein={w_dist:.1f}\")\n\nY_COL = 'grain_yield_kg'  # just for clarity if you reuse\n\n# 1) Pick a robust train range (change quantiles if you want stricter/looser)\nq_low, q_high = np.quantile(np.asarray(y_train_temp, dtype=np.float64), [0.12, 1])\n\n# Optional padding (e.g., allow a tiny buffer beyond train range)\npad = 0.0  # e.g., 0.02 * (q_high - q_low)\nlo, hi = q_low - pad, q_high + pad\n\n# 2) Build mask on TEST using ground-truth yields\nytest = pd.Series(y_test_temp, dtype='float64')\nmask  = (ytest >= lo) & (ytest <= hi)\n\n# 3) Filter test set\nX_test_temp = X_test_temp.loc[mask].reset_index(drop=True)\ny_test_temp = y_test_temp.loc[mask].reset_index(drop=True)\n\ndropped = int((~mask).sum())\nkept = int(mask.sum())\ntotal = int(len(mask))\n\nprint(f\"Train yield window: [{lo:.2f}, {hi:.2f}] (from 12–100 percentiles)\")\nprint(f\"Dropped {dropped}/{total} test rows ({dropped/total:.1%}) as out-of-distribution.\")\nprint(f\"Kept {kept} test rows.\")\n\nks_stat2, ks_p2 = ks_2samp(y_train_temp, y_test_temp)\nw_dist2 = wasserstein_distance(y_train_temp, y_test_temp)\nprint(f\"After filtering: KS={ks_stat2:.3f}, p={ks_p2:.3e}, Wasserstein={w_dist2:.1f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Declare categorical columns\n# If you have OHE columns, list their prefixes. We’ll collect all columns that start with these.\ncat_prefixes = ['region_', 'province_', 'previous_crop_', 'sub_program_']\n\n# Single-label categorical columns (not OHE) to force as categorical (e.g., integer label for crop)\ncat_single_cols = ['crop', 'region', 'province', 'previous_crop', 'sub_program', 'growth_season', 'climate_zone'] \n\n# Build the categorical column list from the frame\ncat_cols_from_prefix = [c for c in X_train_temp.columns if any(c.startswith(p) for p in cat_prefixes)]\ncat_cols = cat_single_cols + cat_cols_from_prefix\ncat_cols = [c for c in cat_cols if c in X_train_temp.columns]  # guard against missing\n\n# Numeric columns = everything else\nnum_cols = [c for c in X_train_temp.columns if c not in cat_cols]\n\n# Prepare X (scale numeric only)\n# Ensure numeric dtype for numeric columns\nX_num = X_train_temp[num_cols].apply(pd.to_numeric, errors='coerce').fillna(0.0)\nX_cat = X_train_temp[cat_cols].copy()\n\n# For OHE dummies, keep them as 0/1; for label-like categoricals (e.g., 'crop'), ensure int\nfor c in cat_cols:\n    # If column looks numeric, keep numeric; otherwise factorize to int codes (rare case)\n    if pd.api.types.is_numeric_dtype(X_cat[c]):\n        X_cat[c] = X_cat[c].fillna(0).astype(int)\n    else:\n        X_cat[c] = pd.factorize(X_cat[c])[0].astype(int)\n\n# Scale numeric only\nscaler = StandardScaler().fit(X_num)\nX_scaled_num = scaler.transform(X_num)\n\n# Combined matrix: [scaled numeric | categorical (unscaled ints)]\nX_train_temp_scaled = np.hstack([X_scaled_num, X_cat.values])\n\n# Categorical feature indices in the combined matrix\ncat_idx = list(range(len(num_cols), len(num_cols) + len(cat_cols)))\n\n# SMOTENC on y-bins\nN_BINS = 5\ny_bins = pd.qcut(pd.Series(y_train_temp, dtype='float64'), q=N_BINS, labels=False, duplicates='drop')\n\nsm = SMOTENC(categorical_features=cat_idx, random_state=42)\nX_all_res, y_bins_res = sm.fit_resample(X_train_temp_scaled, y_bins)\n\n# Split back, inverse-scale numeric, rebuild in original column order\nX_num_scaled_res = X_all_res[:, :len(num_cols)]\nX_cat_res        = X_all_res[:, len(num_cols):]\n\n# Inverse scale numerics\nX_num_res = scaler.inverse_transform(X_num_scaled_res)\ndf_num_res = pd.DataFrame(X_num_res, columns=num_cols, index=None)\n\n# Categorical back to DataFrame, keep ints (0/1 for OHE, 0/1/2 for crop, etc.)\ndf_cat_res = pd.DataFrame(X_cat_res, columns=cat_cols, index=None).astype(int)\n\n# Rebuild in the exact original order\nX_res = pd.concat([df_num_res, df_cat_res], axis=1)\nX_res = X_res[X_train_temp.columns]  # enforce original column order\n\n# Map bins back to continuous y\nbin_to_median_y = pd.Series(y_train_temp, dtype='float64').groupby(y_bins).median()\ny_res = pd.Series(y_bins_res).map(bin_to_median_y).astype('float64').reset_index(drop=True)\n\nprint(f\"Temporal train before: {X_train_temp.shape}  after SMOTENC: {X_res.shape}\")\n\n# Replace temporal train split; y_test_temp is untouched (order preserved)\nX_train_temp = X_res.reset_index(drop=True)\ny_train_temp = y_res.reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Splits Evaluation\n### Distribution of Crops Across Splits","metadata":{}},{"cell_type":"code","source":"quartile_distribution = pd.concat([\n    data.loc[X_train_rand.index.intersection(data.index), 'crop']\n        .value_counts(normalize=True)\n        .rename(\"Random Train\"),\n    data.loc[X_test_rand.index.intersection(data.index), 'crop']\n        .value_counts(normalize=True)\n        .rename(\"Random Test\"),\n    data.loc[X_train_temp.index.intersection(data.index), 'crop']\n        .value_counts(normalize=True)\n        .rename(\"Temporal Train\"),\n    data.loc[X_test_temp.index.intersection(data.index), 'crop']\n        .value_counts(normalize=True)\n        .rename(\"Temporal Test\")\n], axis=1).fillna(0)\n\n# Define crop mapping\ncrop_mapping = {0: \"Barley\", 1: \"Dry Wheat\", 2: \"Soft Wheat\"}\n\n# Map crop labels to their names\nquartile_distribution.index = quartile_distribution.index.map(crop_mapping)\n\n# Plot the distribution\nquartile_distribution.plot(kind='bar', stacked=True, figsize=(10, 6))\nplt.title(\"Distribution of Crops Across Splits\")\nplt.ylabel(\"Proportion\")\nplt.xlabel(\"Crops\")\nplt.legend(title=\"Splits\", loc=\"upper left\", bbox_to_anchor=(1, 1))\nplt.tight_layout()\n\n# Save the plot\nplt.savefig(os.path.join(\"feature_analysis\", \"target_distribution_across_splits.png\"), dpi=300)\n\n# Display the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.471411Z","iopub.status.idle":"2025-04-20T13:37:21.471689Z","shell.execute_reply.started":"2025-04-20T13:37:21.471538Z","shell.execute_reply":"2025-04-20T13:37:21.471581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cosine Similarity\nrandom_similarity = 1 - cosine(quartile_distribution[\"Random Train\"], quartile_distribution[\"Random Test\"])\ntemporal_similarity = 1 - cosine(quartile_distribution[\"Temporal Train\"], quartile_distribution[\"Temporal Test\"])\n\n# KL Divergence\nkl_random = entropy(quartile_distribution[\"Random Train\"], quartile_distribution[\"Random Test\"])\nkl_temporal = entropy(quartile_distribution[\"Temporal Train\"], quartile_distribution[\"Temporal Test\"])\n\n# Shannon Entropy\nentropy_random_train = entropy(quartile_distribution[\"Random Train\"])\nentropy_random_test = entropy(quartile_distribution[\"Random Test\"])\nentropy_temporal_train = entropy(quartile_distribution[\"Temporal Train\"])\nentropy_temporal_test = entropy(quartile_distribution[\"Temporal Test\"])\n\n# Output\nprint(f\"Cosine Similarity (Random Split): {random_similarity:.4f}\")\nprint(f\"Cosine Similarity (Temporal Split): {temporal_similarity:.4f}\")\nprint(f\"KL Divergence (Random Split): {kl_random:.4f}\")\nprint(f\"KL Divergence (Temporal Split): {kl_temporal:.4f}\")\nprint(f\"Shannon Entropy (Random Train): {entropy_random_train:.4f}\")\nprint(f\"Shannon Entropy (Temporal Train): {entropy_temporal_train:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.473048Z","iopub.status.idle":"2025-04-20T13:37:21.473809Z","shell.execute_reply.started":"2025-04-20T13:37:21.473661Z","shell.execute_reply":"2025-04-20T13:37:21.473680Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Distribution of Target Variable","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.kdeplot(y_train_rand, label=\"Random Train\", color=\"blue\", fill=True, alpha=0.3)\nsns.kdeplot(y_test_rand, label=\"Random Test\", color=\"red\", fill=True, alpha=0.3)\nsns.kdeplot(y_train_temp, label=\"Temporal Train\", color=\"green\", fill=True, alpha=0.3)\nsns.kdeplot(y_test_temp, label=\"Temporal Test\", color=\"orange\", fill=True, alpha=0.3)\nplt.title(\"Distribution of Target Variable (Yield)\")\nplt.xlabel(\"Yield (kg)\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(\"feature_analysis\", \"/target_distribution_comparison.png\"), dpi=300)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.474442Z","iopub.status.idle":"2025-04-20T13:37:21.474705Z","shell.execute_reply.started":"2025-04-20T13:37:21.474593Z","shell.execute_reply":"2025-04-20T13:37:21.474605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kolmogorov-Smirnov Test\nks_rand = ks_2samp(y_train_rand, y_test_rand)\nks_temp = ks_2samp(y_train_temp, y_test_temp)\n\n# Descriptive Statistics\ndef describe_data(y):\n    return {\n        \"Mean\": np.round(y.mean(), 4),\n        \"Median\": np.round(y.median(), 4),\n        \"Variance\": np.round(y.var(), 4),\n        \"Skewness\": np.round(skew(y), 4),\n        \"Kurtosis\": np.round(kurtosis(y), 4)\n    }\n\nstats_rand_train = describe_data(y_train_rand)\nstats_rand_test = describe_data(y_test_rand)\nstats_temp_train = describe_data(y_train_temp)\nstats_temp_test = describe_data(y_test_temp)\n\n# Output\nprint(f\"KS Test (Random Split): Statistic={ks_rand.statistic:.4f}, p-value={ks_rand.pvalue:.4f}\")\nprint(f\"KS Test (Temporal Split): Statistic={ks_temp.statistic:.4f}, p-value={ks_temp.pvalue:.4f}\")\nprint(\"Descriptive Statistics (Random Train):\", stats_rand_train)\nprint(\"Descriptive Statistics (Temporal Train):\", stats_temp_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.475907Z","iopub.status.idle":"2025-04-20T13:37:21.476200Z","shell.execute_reply.started":"2025-04-20T13:37:21.476069Z","shell.execute_reply":"2025-04-20T13:37:21.476085Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Machine Learning Models","metadata":{}},{"cell_type":"code","source":"# Function to calculate core metrics\ndef calculate_metrics(y_true, y_pred, n_features=None):\n    y_true = np.asarray(y_true, dtype=np.float64).ravel()\n    y_pred = np.asarray(y_pred, dtype=np.float64).ravel()\n\n    r2 = r2_score(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    mape = mean_absolute_percentage_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    \n    return {\n        \"R2\": r2,\n        \"MAE\": mae,\n        \"MAPE\": mape,\n        \"RMSE\": rmse,\n    }\n\n# Function to calculate grouped metrics\ndef calculate_grouped_metrics(df, group_col, y_true, y_pred):\n    grouped = df.groupby(group_col).apply(\n        lambda group: calculate_metrics(group[y_true], group[y_pred])\n    )\n    return grouped","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.479346Z","iopub.status.idle":"2025-04-20T13:37:21.479665Z","shell.execute_reply.started":"2025-04-20T13:37:21.479465Z","shell.execute_reply":"2025-04-20T13:37:21.479489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ML Models\nmodels = {\n    'LinearRegression': LinearRegression(),\n    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n    'XGBoost 5000': XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42),\n    'XGBoost 50': XGBRegressor(n_estimators=50, learning_rate=0.01, random_state=42),\n    'LightGBM': LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42),\n    'AdaBoost': AdaBoostRegressor(\n        base_estimator=RandomForestRegressor(n_estimators=100, random_state=42),\n        n_estimators=10,\n        learning_rate=0.05,\n        random_state=42\n    ),\n    'CatBoost': CatBoostRegressor(iterations=5000, learning_rate=0.05, verbose=0, random_seed=42),\n    'GradientBoosting 5000': GradientBoostingRegressor(n_estimators=5000, learning_rate=0.05, random_state=42),\n    'GradientBoosting 100': GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, random_state=42),\n    'Ridge': Ridge(alpha=1.0, random_state=42),\n    'Lasso': Lasso(alpha=0.1, random_state=42),\n    'SVR': SVR(kernel='rbf', C=1.0, epsilon=0.1),\n    'ExtraTrees': ExtraTreesRegressor(n_estimators=300, random_state=42, n_jobs=-1),\n    'HistGB': HistGradientBoostingRegressor(learning_rate=0.05, max_iter=5000, random_state=42),\n    'KNN': KNeighborsRegressor(n_neighbors=10, weights='distance'),\n    'ElasticNet': ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42),\n    'Huber': HuberRegressor(alpha=1.0, epsilon=1.35),\n    'Tweedie(p=0.5)': TweedieRegressor(power=0.05, alpha=0.0005, link='log'),\n    'Stacking_ExtraTrees': StackingRegressor(\n        estimators=[\n            ('ExtraTreesRegressor', ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n            ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42)),\n            ('lgbm', LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42))\n        ],\n        final_estimator=ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n    ),\n    'Stacking_LR': StackingRegressor(\n        estimators=[\n            ('ExtraTreesRegressor', ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n            ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42)),\n            ('lgbm', LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42))\n        ],\n        final_estimator=LinearRegression()\n    ),\n    'Stacking_RandomForestRegressor': StackingRegressor(\n        estimators=[\n            ('ExtraTreesRegressor', ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n            ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42)),\n            ('lgbm', LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42))\n        ],\n        final_estimator=RandomForestRegressor(n_estimators=100, random_state=42)\n    ),\n    'Stacking_CatBoostRegressor': StackingRegressor(\n        estimators=[\n            ('ExtraTreesRegressor', ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n            ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42)),\n            ('lgbm', LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42))\n        ],\n        final_estimator=CatBoostRegressor(iterations=5000, learning_rate=0.05, verbose=0, random_seed=42)\n    ),\n    'Stacking_LGBMRegressor': StackingRegressor(\n        estimators=[\n            ('ExtraTreesRegressor', ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n            ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42)),\n            ('lgbm', LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42))\n        ],\n        final_estimator=LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42)\n    ),\n    'Stacking_XGBRegressor': StackingRegressor(\n        estimators=[\n            ('ExtraTreesRegressor', ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1)),\n            ('xgb', XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42)),\n            ('lgbm', LGBMRegressor(n_estimators=5000, learning_rate=0.05, verbose=-1, random_state=42))\n        ],\n        final_estimator=XGBRegressor(n_estimators=5000, learning_rate=0.05, random_state=42)\n    )\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.480812Z","iopub.status.idle":"2025-04-20T13:37:21.481069Z","shell.execute_reply.started":"2025-04-20T13:37:21.480953Z","shell.execute_reply":"2025-04-20T13:37:21.480965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate each model\nresults = {}\ngrouped_results = {}\ny_pred_ensemble_rand = []\ny_pred_ensemble_temp = []\n\nfor model_name, model in models.items():\n    print(f\"\\n Evaluate {model_name}\")\n\n#    sample_weights_rand = X_train_rand['crop'].map({0: 4.0, 1: 1.0, 2: 1.0})\n#    sample_weights_temp = X_train_temp['crop'].map({0: 4.0, 1: 1.0, 2: 1.0})\n\n    # Random Split\n    model.fit(X_train_rand, y_train_rand) #, sample_weight=sample_weights_rand)\n    \n    # >>> ADD (TRAIN preds + TRAIN metrics + TRAIN grouped-by-crop)\n    y_pred_rand_train = model.predict(X_train_rand)\n    rand_train_metrics = calculate_metrics(y_train_rand, y_pred_rand_train)\n\n    rand_train_df = X_train_rand.copy()\n    rand_train_df[\"y_true\"] = np.asarray(y_train_rand).ravel()\n    rand_train_df[\"y_pred\"] = np.asarray(y_pred_rand_train).ravel()\n    grouped_rand_train_crop = calculate_grouped_metrics(rand_train_df, \"crop\", \"y_true\", \"y_pred\")\n\n    # (existing TEST preds + TEST metrics)\n    y_pred_rand = model.predict(X_test_rand)\n    rand_metrics = calculate_metrics(y_test_rand, y_pred_rand)\n    rand_df = X_test_rand.copy()\n    rand_df['y_true'], rand_df['y_pred'] = y_test_rand, y_pred_rand\n    \n    # Save model 1\n    joblib.dump(model, f\"models/{model_name}_random_split.pkl\")\n\n    # Temporal Split\n    model.fit(X_train_temp, y_train_temp)\n    \n    # >>> ADD (TRAIN preds + TRAIN metrics + TRAIN grouped-by-crop)\n    y_pred_temp_train = model.predict(X_train_temp)\n    temp_train_metrics = calculate_metrics(y_train_temp, y_pred_temp_train)\n\n    temp_train_df = X_train_temp.copy()\n    temp_train_df[\"y_true\"] = np.asarray(y_train_temp).ravel()\n    temp_train_df[\"y_pred\"] = np.asarray(y_pred_temp_train).ravel()\n    grouped_temp_train_crop = calculate_grouped_metrics(temp_train_df, \"crop\", \"y_true\", \"y_pred\")\n\n    # (existing TEST preds + TEST metrics)\n    y_pred_temp = model.predict(X_test_temp)\n    temp_metrics = calculate_metrics(y_test_temp, y_pred_temp)\n    temp_df = X_test_temp.copy()\n    temp_df['y_true'], temp_df['y_pred'] = y_test_temp, y_pred_temp\n\n    # Save model 2\n    joblib.dump(model, f\"models/{model_name}_temporal_split.pkl\")\n\n    # Grouped Metrics\n    grouped_rand_crop = calculate_grouped_metrics(rand_df, 'crop', 'y_true', 'y_pred')\n    grouped_temp_crop = calculate_grouped_metrics(temp_df, 'crop', 'y_true', 'y_pred')\n\n    # Store Results\n    # Store Results (>>> ADD Random Train / Temporal Train)\n    results[model_name] = {\n        \"Random Train\": rand_train_metrics,\n        \"Random Split\": rand_metrics,\n        \"Temporal Train\": temp_train_metrics,\n        \"Temporal Split\": temp_metrics\n    }\n\n    grouped_results[model_name] = {\n        \"Random Train Crop\": grouped_rand_train_crop,\n        \"Random Split Crop\": grouped_rand_crop,\n        \"Temporal Train Crop\": grouped_temp_train_crop,\n        \"Temporal Split Crop\": grouped_temp_crop\n    }\n\n    # For ensemble predictions\n    y_pred_ensemble_rand.append(y_pred_rand)\n    y_pred_ensemble_temp.append(y_pred_temp)\n\n# Flatten the results into a DataFrame\ndef flatten_results(results):\n    flattened = []\n    for model, splits in results.items():\n        for split, metrics in splits.items():\n            if isinstance(metrics, dict):\n                metrics['Model'] = model\n                metrics['Split'] = split\n                flattened.append(metrics)\n    return pd.DataFrame(flattened)\n\n# Flatten the results\nresults_df = flatten_results(results)\n\n# Pivot the table for better readability\nresults_pivot = results_df.pivot(index='Model', columns='Split',\n                                 values=['R2', 'MAE', 'MAPE', 'sMAPE', 'RMSE'])\n# Clean up the column names\nresults_pivot.columns = [f\"{metric}_{split}\" for metric, split in results_pivot.columns]\nresults_pivot.reset_index(inplace=True)\nresults_pivot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.482890Z","iopub.status.idle":"2025-04-20T13:37:21.483172Z","shell.execute_reply.started":"2025-04-20T13:37:21.483029Z","shell.execute_reply":"2025-04-20T13:37:21.483041Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Neural Network Models","metadata":{}},{"cell_type":"code","source":"# Prepare data\nscaler = MinMaxScaler()\n\nX_train_rand_scaled = scaler.fit_transform(X_train_rand)\nX_test_rand_scaled = scaler.transform(X_test_rand)\nX_train_temp_scaled = scaler.fit_transform(X_train_temp)\nX_test_temp_scaled = scaler.transform(X_test_temp)\n\ninput_dim = X_train_rand_scaled.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.484278Z","iopub.status.idle":"2025-04-20T13:37:21.484762Z","shell.execute_reply.started":"2025-04-20T13:37:21.484586Z","shell.execute_reply":"2025-04-20T13:37:21.484602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define Neural Network Architectures\n# DNN\ndef dnn(input_dim):\n    model = Sequential([\n        Dense(1024, activation='relu', input_dim=input_dim),\n        BatchNormalization(),\n        Dropout(0.4),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.4),\n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.3),\n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(1, activation='linear')\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n    return model\n\n# Feature Attention NN\ndef feature_attention_nn(input_dim):\n    inputs = Input(shape=(input_dim,))\n    attention_weights = Dense(input_dim, activation='softmax', name=\"Attention_Weights\")(inputs)\n    weighted_inputs = Multiply()([inputs, attention_weights])\n\n    x = Dense(1024, activation='relu')(weighted_inputs)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    x = Dense(128, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(1, activation='linear')(x)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n    return model\n\n# Residual Network\ndef resnet(input_dim):\n    inputs = Input(shape=(input_dim,))\n    x = Dense(512, activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    shortcut = Dense(256, activation='linear')(inputs)\n    x = Add()([x, shortcut])\n\n    x = Dense(128, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dense(64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    outputs = Dense(1, activation='linear')(x)\n\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n    return model\n\n# Transformer\ndef transformer(input_dim):\n    # Input layer\n    inputs = Input(shape=(input_dim,))\n\n    # Expand dimensions to create a sequence-like structure\n    reshaped_inputs = Reshape((1, input_dim))(inputs)  # Sequence length = 1, feature dim = input_dim\n\n    # Multi-Head Attention\n    attention_output = MultiHeadAttention(num_heads=4, key_dim=input_dim // 4)(reshaped_inputs, reshaped_inputs)\n    attention_output = LayerNormalization()(attention_output + reshaped_inputs)  # Skip connection\n\n    # Feedforward Network\n    ffn = Dense(input_dim, activation='relu')(attention_output)  # Ensure matching dimensions\n    ffn = Dense(input_dim, activation='relu')(ffn)  # Match dimensions with attention_output\n    ffn = LayerNormalization()(ffn + attention_output)  # Skip connection\n\n    # Remove sequence dimension for final output\n    flattened_ffn = Reshape((input_dim,))(ffn)  # Flatten to (None, input_dim)\n\n    # Output layer\n    outputs = Dense(1, activation='linear')(flattened_ffn)\n\n    # Compile the model\n    model = Model(inputs=inputs, outputs=outputs, name=\"Transformer\")\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n\n    return model\n\n# Autoencoder Regressor\ndef autoencoder_regressor(input_dim):\n    inputs = Input(shape=(input_dim,))\n    encoded = Dense(256, activation='relu')(inputs)\n    encoded = BatchNormalization()(encoded)\n    encoded = Dense(128, activation='relu')(encoded)\n    encoded = BatchNormalization()(encoded)\n\n    decoded = Dense(256, activation='relu')(encoded)\n    decoded = BatchNormalization()(decoded)\n    decoded = Dense(input_dim, activation='linear')(decoded)\n\n    regression_output = Dense(1, activation='linear')(encoded)\n\n    model = Model(inputs=inputs, outputs=regression_output)\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n    return model\n\n# Deep & Cross Network (DCN v2 style)\nfrom tensorflow.keras import layers, Model, Input\ndef dcn_v2(input_dim, depth=5, hidden=(512,256,128), dropout=0.2):\n    inp = Input((input_dim,))\n    # Cross network\n    x0 = inp\n    xc = x0\n    for _ in range(depth):\n        xc = xc + layers.Dense(input_dim, use_bias=True)(xc * x0)\n        xc = layers.LayerNormalization()(xc)\n    # Deep tower\n    xd = inp\n    for h in hidden:\n        xd = layers.Dense(h, activation='relu')(xd)\n        xd = layers.Dropout(dropout)(xd)\n    x = layers.Concatenate()([xc, xd])\n    out = layers.Dense(1)(x)\n    m = Model(inp, out, name=\"DCNv2\")\n    m.compile(optimizer=Adam(1e-3), loss='mse', metrics=['mae'])\n    return m\n\n# Quantile MLP (uncertainty bands via pinball loss)\n@register_keras_serializable(package=\"Custom\", name=\"PinballLoss\")\nclass PinballLoss(tf.keras.losses.Loss):\n    def __init__(self, tau=0.5, **kwargs):\n        super().__init__(**kwargs)\n        self.tau = float(tau)\n\n    def call(self, y_true, y_pred):\n        e = y_true - y_pred\n        return tf.reduce_mean(tf.maximum(self.tau * e, (self.tau - 1.0) * e))\n\n    def get_config(self):\n        return {\"tau\": self.tau}\n\n# Backward-compat: if older saved models reference a function literally named \"qloss\"\n@register_keras_serializable(package=\"Custom\", name=\"qloss\")\ndef qloss(y_true, y_pred):\n    tau = 0.5\n    e = y_true - y_pred\n    return tf.reduce_mean(tf.maximum(tau * e, (tau - 1.0) * e))\n\ndef quantile_mlp(input_dim, tau=0.5):\n    inp = tf.keras.Input((input_dim,))\n    x = tf.keras.layers.Dense(256, activation='relu')(inp)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    out = tf.keras.layers.Dense(1)(x)\n    m = tf.keras.Model(inp, out, name=f\"QMLP_tau{tau}\")\n    m.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n              loss=PinballLoss(tau=tau),\n              metrics=['mae'])\n    return m","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.485831Z","iopub.status.idle":"2025-04-20T13:37:21.486146Z","shell.execute_reply.started":"2025-04-20T13:37:21.486032Z","shell.execute_reply":"2025-04-20T13:37:21.486044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save architectures as images for visualization\narchitecture_dir = \"architectures\"\nos.makedirs(architecture_dir, exist_ok=True)\nmodel_functions = [\n    dnn,\n    feature_attention_nn,\n    transformer,           # current (seq_len=1) transformer\n    resnet,\n    autoencoder_regressor,\n    dcn_v2,                # added\n    lambda d: quantile_mlp(d, 0.5),  # added (τ=0.5 / median)\n]\n\nmodel_names = [\n    'DNN',\n    'FeatureAttentionNN',\n    'Transformer',\n    'ResNet',\n    'AutoencoderRegressor',\n    'DCNv2',\n    'QMLP_tau0.5',\n]\n\nn = len(model_functions)\ncols = min(4, n)                 # up to 4 per row\nrows = math.ceil(n / cols)\n\nfig, axs = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\naxs = axs if isinstance(axs, (list, np.ndarray)) else [axs]\naxs = np.array(axs).reshape(rows, cols)\n\nfor idx, (fn, name) in enumerate(zip(model_functions, model_names)):\n    r, c = divmod(idx, cols)\n    model = fn(input_dim)  # assumes you have input_dim defined\n    path = f\"{architecture_dir}/{name}_architecture.png\"\n    plot_model(model, to_file=path, show_shapes=True, show_layer_names=True)\n\n    img = plt.imread(path)\n    axs[r, c].imshow(img)\n    axs[r, c].axis('off')\n    axs[r, c].set_title(name)\n\n# hide any unused subplots\nfor k in range(n, rows*cols):\n    r, c = divmod(k, cols)\n    axs[r, c].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.486910Z","iopub.status.idle":"2025-04-20T13:37:21.487151Z","shell.execute_reply.started":"2025-04-20T13:37:21.487040Z","shell.execute_reply":"2025-04-20T13:37:21.487050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- NN RESULTS in the same structure as `results` ----\nresults_nn_dict = {}\n\nfor split_name, (X_train_scaled, y_train, X_test_scaled, y_test) in zip(\n    [\"Random Split\", \"Temporal Split\"],\n    [\n        (X_train_rand_scaled, y_train_rand, X_test_rand_scaled, y_test_rand),\n        (X_train_temp_scaled, y_train_temp, X_test_temp_scaled, y_test_temp),\n    ],\n):\n    for model_fn, model_name in zip(model_functions, model_names):\n        print(f\"\\n Evaluate {model_name} - {split_name}\")\n\n        model = model_fn(input_dim)\n        early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n\n        model.fit(\n            X_train_scaled, y_train,\n            validation_split=0.2,                 # uses TRAIN-only validation (no test leakage)\n            epochs=5000, batch_size=32, verbose=0,\n            callbacks=[early_stopping, reduce_lr]\n        )\n\n        # >>> TRAIN metrics (for ensemble weights)\n        y_pred_train = model.predict(X_train_scaled, verbose=0).ravel()\n        ms_train = calculate_metrics(y_train, y_pred_train)\n\n        # >>> TEST metrics (kept for reporting)\n        y_pred_test = model.predict(X_test_scaled, verbose=0).ravel()\n        ms_test = calculate_metrics(y_test, y_pred_test)\n\n        # store in SAME structure as `results`\n        results_nn_dict.setdefault(model_name, {})\n\n        if split_name == \"Random Split\":\n            results_nn_dict[model_name][\"Random Train\"] = ms_train \n            results_nn_dict[model_name][\"Random Split\"] = ms_test\n            base_train_df = X_train_rand\n            base_test_df  = X_test_rand\n        else:\n            results_nn_dict[model_name][\"Temporal Train\"] = ms_train\n            results_nn_dict[model_name][\"Temporal Split\"] = ms_test\n            base_train_df = X_train_temp\n            base_test_df  = X_test_temp\n\n        # grouped TRAIN crop metrics\n        df_train = base_train_df.copy()\n        df_train[\"y_true\"] = np.asarray(y_train).ravel()\n        df_train[\"y_pred\"] = np.asarray(y_pred_train).ravel()\n        gr_train = calculate_grouped_metrics(df_train, \"crop\", \"y_true\", \"y_pred\")\n\n        # grouped TEST crop metrics\n        df_test = base_test_df.copy()\n        df_test[\"y_true\"] = np.asarray(y_test).ravel()\n        df_test[\"y_pred\"] = np.asarray(y_pred_test).ravel()\n        gr_test = calculate_grouped_metrics(df_test, \"crop\", \"y_true\", \"y_pred\")\n\n        grouped_results.setdefault(model_name, {})\n        if split_name == \"Random Split\":\n            grouped_results[model_name][\"Random Train Crop\"] = gr_train\n            grouped_results[model_name][\"Random Split Crop\"] = gr_test\n        else:\n            grouped_results[model_name][\"Temporal Train Crop\"] = gr_train\n            grouped_results[model_name][\"Temporal Split Crop\"] = gr_test\n\n        # save NN model (one per split)\n        model.save(f\"models/{model_name}_{split_name.lower().replace(' ', '_')}.keras\")\n\n# ---- flatten & pivot NN results to match `results_pivot` ----\nresults_nn_df = flatten_results(results_nn_dict)  # reuses your helper\nresults_nn_pivot = results_nn_df.pivot(index='Model', columns='Split',\n                                       values=['R2','MAE','MAPE','sMAPE','RMSE'])\nresults_nn_pivot.columns = [f\"{m}_{s}\" for m, s in results_nn_pivot.columns]\nresults_nn_pivot = results_nn_pivot.reset_index()\nresults_nn_pivot","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation\n## Overall Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Appending the results_nn_final to results_pivot\ndef merge_results(base, extra, prefer='extra'):\n    \"\"\"\n    Merge two nested dicts of the form:\n      {model_name: {'Random Split': {...}, 'Temporal Split': {...}}}\n    prefer: 'extra' -> overwrite base with extra on conflicts, 'base' -> keep base.\n    \"\"\"\n    out = copy.deepcopy(base)\n    for model, splits in extra.items():\n        if model not in out:\n            out[model] = {}\n        for split_name, metrics in splits.items():\n            if split_name in out[model]:\n                if prefer == 'extra':\n                    out[model][split_name] = metrics\n                # else keep base metrics\n            else:\n                out[model][split_name] = metrics\n    return out\n\n# Merge\nresults = merge_results(results, results_nn_dict, prefer='extra')\n\n# (Optional) Flatten + pivot again if you want a combined table\ncombined_df = flatten_results(results)\ncombined_pivot = combined_df.pivot(index='Model', columns='Split',\n                                   values=['R2','MAE','MAPE','sMAPE','RMSE'])\ncombined_pivot.columns = [f\"{m}_{s}\" for m, s in combined_pivot.columns]\ncombined_results = combined_pivot.reset_index()\ncombined_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.489875Z","iopub.status.idle":"2025-04-20T13:37:21.490108Z","shell.execute_reply.started":"2025-04-20T13:37:21.489994Z","shell.execute_reply":"2025-04-20T13:37:21.490005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Selecting the top 3 models based on MAPE for Random and Temporal Splits\ntop_3_random_models = combined_results.nsmallest(3, \"MAPE_Random Split\")[\"Model\"].tolist()\ntop_3_temporal_models = combined_results.nsmallest(3, \"MAPE_Temporal Split\")[\"Model\"].tolist()\n\n# Function to plot and save prediction vs actual values\ndef plot_and_save(model_name, y_test, y_pred, split_name):\n    plt.figure(figsize=(7, 7))\n    plt.scatter(y_test, y_pred, alpha=0.7, label=\"Predicted vs Actual\")\n    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label=\"Perfect Prediction\")\n    plt.title(f\"Predicted vs Actual - {model_name} - {split_name}\")\n    plt.xlabel(\"Actual Values\")\n    plt.ylabel(\"Predicted Values\")\n    plt.legend()\n    plt.grid()\n    plt.tight_layout()\n    plt.savefig(f\"results/Predicted vs Actual - {model_name} - {split_name}.png\")\n    plt.show()\n    plt.close()\n    \n# Function to extract predictions and ground truth\ndef get_predictions_and_actuals(model_name, split_type):\n    if split_type == \"Random Split\":\n        y_test = y_test_rand\n        y_pred = y_pred_ensemble_rand[top_3_random_models.index(model_name)]\n    elif split_type == \"Temporal Split\":\n        y_test = y_test_temp\n        y_pred = y_pred_ensemble_temp[top_3_temporal_models.index(model_name)]\n    return y_test, y_pred\n\n# Plotting and saving the predictions for the top models\nfor model_name in top_3_random_models:\n    y_test, y_pred = get_predictions_and_actuals(model_name, \"Random Split\")\n    plot_and_save(model_name, y_test, y_pred, \"Random Split\")\n\nfor model_name in top_3_temporal_models:\n    y_test, y_pred = get_predictions_and_actuals(model_name, \"Temporal Split\")\n    plot_and_save(model_name, y_test, y_pred, \"Temporal Split\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.491776Z","iopub.status.idle":"2025-04-20T13:37:21.491996Z","shell.execute_reply.started":"2025-04-20T13:37:21.491889Z","shell.execute_reply":"2025-04-20T13:37:21.491898Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Spatial Generalization Checks","metadata":{}},{"cell_type":"code","source":"# ---- USER SETTINGS ----\nBEST_MODEL_NAME = \"ExtraTrees\"   # change if your key differs in `models`\nSITE_DECIMALS = 5                # site_id = rounded(lat,lon); adjust (3-5) based on coordinate precision\nRANDOM_STATE = 42\n\ndef _find_first_col(df, candidates):\n    for c in candidates:\n        if c in df.columns:\n            return c\n    return None\n\ndef ensure_site_id(df: pd.DataFrame, decimals: int = 4) -> pd.Series:\n    \"\"\"\n    Create/return a site_id Series.\n    Priority:\n      1) use existing site_id if present\n      2) build from (lat, lon) rounded\n      3) fallback to (province) if no coords available (still useful for reviewer)\n    \"\"\"\n    if \"site_id\" in df.columns:\n        return df[\"site_id\"].astype(str)\n\n    lat_col = _find_first_col(df, [\"lat\", \"latitude\", \"Latitude\", \"LAT\", \"y\", \"y_coord\", \"Y\", \"Y_coord\"])\n    lon_col = _find_first_col(df, [\"lon\", \"longitude\", \"Longitude\", \"LON\", \"x\", \"x_coord\", \"X\", \"X_coord\"])\n\n    if lat_col is not None and lon_col is not None:\n        lat = df[lat_col].astype(float).round(decimals)\n        lon = df[lon_col].astype(float).round(decimals)\n        return (lat.astype(str) + \"_\" + lon.astype(str)).astype(str)\n\n    prov_col = _find_first_col(df, [\"province\", \"Province\"])\n    if prov_col is not None:\n        # province-level grouping (coarser than site-level, but better than random rows)\n        return df[prov_col].astype(str)\n\n    raise ValueError(\"Could not build site_id: no 'site_id', no lat/lon, and no province column found.\")\n\ndef evaluate_model(model, X_train, y_train, X_test, y_test):\n    \"\"\"Fit -> predict -> metrics (uses your existing calculate_metrics).\"\"\"\n    model.fit(X_train, y_train)\n    y_hat = model.predict(X_test)\n    return calculate_metrics(y_test, y_hat), y_hat\n\n# Pick the base estimator\nif BEST_MODEL_NAME not in models:\n    raise KeyError(f\"'{BEST_MODEL_NAME}' not found in models.keys():\\n{list(models.keys())}\")\n\nbase_est = clone(models[BEST_MODEL_NAME])\n\n# Unseen-site-only metrics in RANDOM split\n# Add/compute site_id for train/test (does NOT modify original frames unless you assign it)\nsite_train = ensure_site_id(X_train_rand, decimals=SITE_DECIMALS)\nsite_test  = ensure_site_id(X_test_rand,  decimals=SITE_DECIMALS)\n\ntrain_site_set = set(site_train.tolist())\nmask_unseen = ~site_test.isin(train_site_set)\n\n# Fit on random train, evaluate on all random test\nrand_all_metrics, yhat_rand_all = evaluate_model(\n    clone(base_est), X_train_rand, y_train_rand, X_test_rand, y_test_rand\n)\n\n# Evaluate on unseen-site rows only\nX_test_unseen = X_test_rand.loc[mask_unseen]\n# y_test may be Series or ndarray; align robustly to X_test_unseen row order\nif isinstance(y_test_rand, (pd.Series, pd.DataFrame)):\n    y_test_unseen = y_test_rand.loc[X_test_unseen.index]\nelse:\n    # assumes y_test_rand is in the same row order as X_test_rand\n    y_test_unseen = np.asarray(y_test_rand)[mask_unseen.values]\n\n# Need predictions for unseen rows\n# If yhat_rand_all aligned to X_test_rand order, subset by mask\nyhat_rand_unseen = np.asarray(yhat_rand_all)[mask_unseen.values]\nrand_unseen_metrics = calculate_metrics(y_test_unseen, yhat_rand_unseen)\n\n# Group-aware split by site_id (new exp)\n# Build full X/y from the random-split parts (same preprocessing/features)\nX_full = pd.concat([X_train_rand, X_test_rand], axis=0)\ny_full = pd.concat([pd.Series(y_train_rand, index=X_train_rand.index),\n                    pd.Series(y_test_rand,  index=X_test_rand.index)], axis=0)\n\ngroups_full = ensure_site_id(X_full, decimals=SITE_DECIMALS)\n\ngss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\ntrain_idx, test_idx = next(gss.split(X_full, y_full, groups=groups_full))\n\nX_train_g = X_full.iloc[train_idx]\ny_train_g = y_full.iloc[train_idx]\nX_test_g  = X_full.iloc[test_idx]\ny_test_g  = y_full.iloc[test_idx]\n\ngroup_split_metrics, _ = evaluate_model(\n    clone(base_est), X_train_g, y_train_g, X_test_g, y_test_g\n)\n\n# Summarize in a small table (paper-ready)\nsummary_rows = [\n    {\n        \"Evaluation\": \"Random split (all test rows)\",\n        \"n_test_rows\": len(X_test_rand),\n        \"n_test_sites\": site_test.nunique(),\n        **rand_all_metrics\n    },\n    {\n        \"Evaluation\": \"Random split (unseen-site rows only)\",\n        \"n_test_rows\": int(mask_unseen.sum()),\n        \"n_test_sites\": site_test[mask_unseen].nunique(),\n        **rand_unseen_metrics\n    },\n    {\n        \"Evaluation\": \"Group-aware split by site (hold-out sites)\",\n        \"n_test_rows\": len(X_test_g),\n        \"n_test_sites\": ensure_site_id(X_test_g, decimals=SITE_DECIMALS).nunique(),\n        **group_split_metrics\n    },\n]\n\nspatial_generalization_table = pd.DataFrame(summary_rows)\n\n# Keep only the core metrics you report in the paper (adjust if your calculate_metrics returns more)\nkeep_cols = [\"Evaluation\", \"n_test_rows\", \"n_test_sites\", \"R2\", \"MAE\", \"MAPE\", \"sMAPE\", \"RMSE\"]\nkeep_cols = [c for c in keep_cols if c in spatial_generalization_table.columns]\nspatial_generalization_table = spatial_generalization_table[keep_cols]\n\ndisplay(spatial_generalization_table)\n\nprint(\"\\nNotes:\")\nprint(f\"- BEST_MODEL_NAME = {BEST_MODEL_NAME}\")\nprint(f\"- site_id built from rounded(lat,lon) with decimals={SITE_DECIMALS} (or province fallback if no coords).\")\nprint(\"- If any target-derived features exist (e.g., per-location mean yield), recompute them inside each split to avoid leakage.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Crop-Specific Model Evaluation","metadata":{}},{"cell_type":"code","source":"wide_table_with_crops = []\n\n# Iterate through each model and its splits\nfor model, splits in grouped_results.items():\n    # Iterate through each split (e.g., 'Random Split Crop', 'Temporal Split Crop')\n    for split, data in splits.items():\n        # Iterate through each crop\n        for crop_index, metrics in enumerate(data):\n            # Initialize a row dictionary for the current crop\n            row = {'Model': model, 'Split': split, 'Crop': crop_index}\n            # Add metrics to the row\n            row.update(metrics)\n            # Append the row to the wide_table\n            wide_table_with_crops.append(row)\n\n# Convert the table list into a DataFrame\nwide_results_table_with_crops = pd.DataFrame(wide_table_with_crops)\n\n# Pivot the DataFrame to the desired wide format\nwide_results_table = wide_results_table_with_crops.pivot(\n    index=['Model', 'Crop'],\n    columns='Split',\n    values=['R2', 'MAE', 'MAPE', 'sMAPE', 'RMSE']\n)\n\n# Flatten the MultiIndex columns\nwide_results_table.columns = [\n    f\"{metric}_{split}\" for metric, split in wide_results_table.columns\n]\n\n# Reset index to make it a clean DataFrame\nwide_results_table.reset_index(inplace=True)\nwide_results_table","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.493076Z","iopub.status.idle":"2025-04-20T13:37:21.493303Z","shell.execute_reply.started":"2025-04-20T13:37:21.493187Z","shell.execute_reply":"2025-04-20T13:37:21.493199Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble Learning","metadata":{}},{"cell_type":"code","source":"# Define helper function to load models\ndef load_model(filepath):\n    import joblib\n    import tensorflow as tf\n    if filepath.endswith(\".pkl\"):\n        return joblib.load(filepath)\n    elif filepath.endswith(\".keras\"):\n        # compile=False is fine for inference; keeps things robust\n        return tf.keras.models.load_model(\n            filepath,\n            custom_objects={\"PinballLoss\": PinballLoss, \"qloss\": qloss},\n            compile=False\n        )\n    else:\n        raise ValueError(f\"Unsupported file format for {filepath}\")\n\nEPS = 1e-9\n\ndef safe_inverse_weights(scores):\n    \"\"\"Inverse-weighting with protection against 0/inf and renormalization.\"\"\"\n    arr = np.asarray(scores, dtype=np.float64)\n    arr = np.where(arr <= 0, EPS, arr)              # avoid 1/0\n    inv = 1.0 / arr\n    inv = np.nan_to_num(inv, nan=0.0, posinf=0.0, neginf=0.0)\n    s = inv.sum()\n    return (inv / s) if s > 0 else np.ones_like(inv) / len(inv)\n\ndef predict_1d(model, X):\n    \"\"\"Predict and return a clean 1-D float64 vector; raise if non-finite.\"\"\"\n    y = model.predict(X)\n    y = np.asarray(y, dtype=np.float64).ravel()\n    if not np.isfinite(y).all():\n        raise ValueError(\"non-finite predictions\")\n    return y\n\ndef to_1d_pred(yhat, n_expected):\n    yhat = np.asarray(yhat)\n    if yhat.ndim == 2 and yhat.shape[1] == 1:        # (n,1) -> (n,)\n        yhat = yhat.ravel()\n    elif yhat.ndim == 2 and yhat.shape[0] == yhat.shape[1] == n_expected:\n        yhat = np.diag(yhat)                         # (n,n) -> diag(n,)\n    elif yhat.ndim > 1:\n        yhat = yhat.reshape(-1)\n    return yhat[:n_expected].astype(float)\n\nensemble_results_crops = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.493964Z","iopub.status.idle":"2025-04-20T13:37:21.494170Z","shell.execute_reply.started":"2025-04-20T13:37:21.494073Z","shell.execute_reply":"2025-04-20T13:37:21.494082Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Unified Ensemble Learning","metadata":{}},{"cell_type":"code","source":"ensemble_sizes = list(range(2, 6))\nensemble_results = []\n\nfor n in ensemble_sizes:\n    # pick top-N by TRAIN sMAPE (NOT test)\n    sorted_models_rand = sorted(\n        {k: v for k, v in results.items() if \"Ensemble\" not in k}.items(),\n        key=lambda x: x[1][\"Random Train\"][\"sMAPE\"]\n    )[:n]\n    sorted_models_temp = sorted(\n        {k: v for k, v in results.items() if \"Ensemble\" not in k}.items(),\n        key=lambda x: x[1][\"Temporal Train\"][\"sMAPE\"]\n    )[:n]\n\n    top_model_names_rand = [m[0] for m in sorted_models_rand]\n    top_model_names_temp = [m[0] for m in sorted_models_temp]\n\n    # weights from TRAIN sMAPE (NOT test)\n    weights_rand = safe_inverse_weights(\n        [results[m][\"Random Train\"][\"sMAPE\"] for m in top_model_names_rand]\n    )\n    weights_temp = safe_inverse_weights(\n        [results[m][\"Temporal Train\"][\"sMAPE\"] for m in top_model_names_temp]\n    )\n\n    # --- RANDOM SPLIT ENSEMBLE ---\n    preds_rand, used_w_rand, used_names_rand = [], [], []\n    for w, model_name in zip(weights_rand, top_model_names_rand):\n        model_path = f\"models/{model_name}_random_split\"\n        if os.path.exists(f\"{model_path}.pkl\"):\n            model = load_model(f\"{model_path}.pkl\")\n        elif os.path.exists(f\"{model_path}.keras\"):\n            model = load_model(f\"{model_path}.keras\")\n        else:\n            print(f\"⚠️ Not found: {model_path}.pkl/.keras\")\n            continue\n        try:\n            y_hat = predict_1d(model, X_test_rand)\n            preds_rand.append(y_hat)\n            used_w_rand.append(w)\n            used_names_rand.append(model_name)\n        except Exception as e:\n            print(f\"⚠️ Skipping {model_name} (random): {e}\")\n\n    if preds_rand:\n        used_w_rand = np.asarray(used_w_rand, dtype=np.float64)\n        used_w_rand /= used_w_rand.sum()  # renormalize to 1\n        stack = np.vstack(preds_rand)     # shape (k, n)\n        y_pred_ensemble_rand = np.average(stack, axis=0, weights=used_w_rand)\n    else:\n        y_pred_ensemble_rand = np.full_like(y_test_rand, fill_value=np.nan, dtype=np.float64)\n\n    # --- TEMPORAL SPLIT ENSEMBLE ---\n    preds_temp, used_w_temp, used_names_temp = [], [], []\n    for w, model_name in zip(weights_temp, top_model_names_temp):\n        model_path = f\"models/{model_name}_temporal_split\"\n        if os.path.exists(f\"{model_path}.pkl\"):\n            model = load_model(f\"{model_path}.pkl\")\n        elif os.path.exists(f\"{model_path}.keras\"):\n            model = load_model(f\"{model_path}.keras\")\n        else:\n            print(f\"⚠️ Not found: {model_path}.pkl/.keras\")\n            continue\n        try:\n            y_hat = predict_1d(model, X_test_temp)\n            preds_temp.append(y_hat)\n            used_w_temp.append(w)\n            used_names_temp.append(model_name)\n        except Exception as e:\n            print(f\"⚠️ Skipping {model_name} (temporal): {e}\")\n\n    if preds_temp:\n        used_w_temp = np.asarray(used_w_temp, dtype=np.float64)\n        used_w_temp /= used_w_temp.sum()\n        stack = np.vstack(preds_temp)\n        y_pred_ensemble_temp = np.average(stack, axis=0, weights=used_w_temp)\n    else:\n        y_pred_ensemble_temp = np.full_like(y_test_temp, fill_value=np.nan, dtype=np.float64)\n\n    # final safety: replace any remaining non-finite with the median of y_true\n    y_pred_ensemble_rand = np.nan_to_num(y_pred_ensemble_rand, nan=float(np.nanmedian(y_test_rand)))\n    y_pred_ensemble_temp = np.nan_to_num(y_pred_ensemble_temp, nan=float(np.nanmedian(y_test_temp)))\n\n    # metrics\n    ensemble_rand_metrics = calculate_metrics(y_test_rand, y_pred_ensemble_rand)\n    ensemble_temp_metrics = calculate_metrics(y_test_temp, y_pred_ensemble_temp)\n\n    ensemble_results.append({\n        'Model': f\"Ensemble_{n}\",\n        'Number of Models': n,\n        'Model Names (Random Split)': ', '.join(used_names_rand),\n        'Model Names (Temporal Split)': ', '.join(used_names_temp),\n        **{f\"{m}_Random Split\": v for m, v in ensemble_rand_metrics.items()},\n        **{f\"{m}_Temporal Split\": v for m, v in ensemble_temp_metrics.items()}\n    })\n\nensemble_results_df = pd.DataFrame(ensemble_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.495737Z","iopub.status.idle":"2025-04-20T13:37:21.496044Z","shell.execute_reply.started":"2025-04-20T13:37:21.495877Z","shell.execute_reply":"2025-04-20T13:37:21.495892Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diebold-Mariano Test of Ensemble Learning ","metadata":{}},{"cell_type":"code","source":"# Perform Diebold-Mariano Test for Top Ensembles for Random and Temporal Splits\ndm_test_results = []\n\nBASE_DIR = \"/kaggle/working/models\" \n\n# Define DM Test function\ndef dm_test(y_true, y_pred1, y_pred2, h=1, loss=\"sMAPE\"):\n    \"\"\"\n    Perform Diebold-Mariano test.\n\n    Parameters:\n    - y_true: Array-like, true values.\n    - y_pred1: Array-like, predictions from Model 1.\n    - y_pred2: Array-like, predictions from Model 2.\n    - h: Int, forecast horizon (default=1).\n    - loss: String, loss function ('MSE' or 'MAE').\n\n    Returns:\n    - DM statistic and p-value.\n    \"\"\"\n    \n    e1 = y_true - y_pred1\n    e2 = y_true - y_pred2\n    d = e1**2 - e2**2 if loss == \"sMAPE\" else np.abs(e1) - np.abs(e2)\n    d_mean = np.mean(d)\n    n = len(d)\n    gamma = np.zeros(h)\n    for lag in range(h):\n        gamma[lag] = np.sum((d[:-lag] - d_mean) * (d[lag:] - d_mean)) / (n - lag) if lag > 0 else np.var(d)\n    dm_stat = d_mean / np.sqrt((gamma[0] + 2 * np.sum(gamma[1:])) / n)\n    p_value = 2 * (1 - norm.cdf(np.abs(dm_stat)))\n    return dm_stat, p_value\n\n\ndef variants(model_name: str, split: str):\n    \"\"\"Generate candidate filenames for robustness.\"\"\"\n    exact = f\"{model_name}_{split}\"\n    us    = exact.replace(' ', '_')\n    lower = exact.lower()\n    lower_us = lower.replace(' ', '_')\n    return [exact, us, lower, lower_us]\n\ndef find_model_file(model_name: str, split: str):\n    \"\"\"Try .pkl then .keras across several name variants and return first match (full path).\"\"\"\n    for stem in variants(model_name, split):\n        for ext in (\".pkl\", \".keras\"):\n            path = os.path.join(BASE_DIR, stem + ext)\n            if os.path.exists(path):\n                return path\n    # fallback: glob case-insensitive on split\n    pattern = os.path.join(BASE_DIR, f\"*{split}.*\")\n    for p in glob.glob(pattern):\n        # crude match: contains model name tokens ignoring case/underscores\n        mnorm = re.sub(r'[^a-z0-9]+','', model_name.lower())\n        pnorm = re.sub(r'[^a-z0-9]+','', os.path.basename(p).lower())\n        if mnorm in pnorm:\n            return p\n    return None\n\ndef load_any_model(path: str):\n    if path.endswith(\".pkl\"):\n        import joblib\n        return joblib.load(path), 'sk'\n    elif path.endswith(\".keras\"):\n        return keras.models.load_model(path), 'keras'\n    else:\n        return None, None\n\ndef predict_any(model, kind, X):\n    X_ = X.values if hasattr(X, \"values\") else X\n    yhat = model.predict(X_, verbose=0) if kind == 'keras' else model.predict(X_)\n    yhat = np.asarray(yhat)\n    if yhat.ndim == 2 and yhat.shape[1] == 1:\n        yhat = yhat.ravel()\n    elif yhat.ndim == 2 and yhat.shape[0] == yhat.shape[1]:\n        yhat = np.diag(yhat)  # guard against accidental (n,n)\n    elif yhat.ndim > 1:\n        yhat = yhat.reshape(-1)\n    return yhat\n\ndef get_ensemble_predictions(models, X_test, split_type):\n    preds = {}\n    for name in models:\n        path = find_model_file(name, split_type)\n        print(path or f\"⚠️ Not found for {name} / {split_type}\")\n        if not path: \n            continue\n        model, kind = load_any_model(path)\n        preds[name] = predict_any(model, kind, X_test)\n    return preds\n\n# Extract top #1 ensemble for Random and Temporal splits\ntop_random_ensemble = ensemble_results_df.iloc[0]  # First row corresponds to top ensemble for Random Split\ntop_temporal_ensemble = ensemble_results_df.iloc[0]  # First row corresponds to top ensemble for Temporal Split\n\n# Parse model names for each ensemble\ntop_random_models = top_random_ensemble['Model Names (Random Split)'].split(', ')\ntop_temporal_models = top_temporal_ensemble['Model Names (Temporal Split)'].split(', ')\n\n# Predictions dictionary for ensembles\nmodel_predictions = {\n    'Random Split': {},\n    'Temporal Split': {}\n}\n\n# top_random_models, top_temporal_models as before\npred_random   = get_ensemble_predictions(top_random_models,   X_test_rand, 'random_split')\npred_temporal = get_ensemble_predictions(top_temporal_models, X_test_temp,  'temporal_split')\n\n# Load predictions for Random and Temporal splits\nmodel_predictions['Random Split'] = pred_random\nmodel_predictions['Temporal Split'] = pred_temporal\n\n# DM Test for all model pairs within each split\nfor split_type, y_test, predictions in [(\"Random Split\", y_test_rand, model_predictions['Random Split']), \n                                        (\"Temporal Split\", y_test_temp, model_predictions['Temporal Split'])]:\n    model_names = list(predictions.keys())\n    for i, model_name_1 in enumerate(model_names):\n        for j, model_name_2 in enumerate(model_names):\n            if i >= j:  # Avoid duplicate comparisons and self-comparisons\n                continue\n\n            # Get predictions for the two models\n            y_pred1 = predictions[model_name_1]\n            y_pred2 = predictions[model_name_2]\n\n            # Calculate DM test statistics\n            dm_stat, p_value = dm_test(y_test, y_pred1, y_pred2, loss=\"sMAPE\")\n\n            # Store results\n            dm_test_results.append({\n                'Model 1': model_name_1,\n                'Model 2': model_name_2,\n                'Split': split_type,\n                'DM Statistic': dm_stat,\n                'P-Value': p_value\n            })\n\n# Convert results to DataFrame\ndm_test_results_df = pd.DataFrame(dm_test_results)\n\n# Display DM Test Results Table\ndm_test_results_df.sort_values(by=['Split', 'P-Value'], inplace=True)\ndm_test_results_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.497321Z","iopub.status.idle":"2025-04-20T13:37:21.497675Z","shell.execute_reply.started":"2025-04-20T13:37:21.497468Z","shell.execute_reply":"2025-04-20T13:37:21.497504Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Crop-Specific Ensemble Model Evaluation","metadata":{}},{"cell_type":"code","source":"for n in ensemble_sizes:\n    for crop in wide_results_table_with_crops[\"Crop\"].unique():\n        crop_results = wide_results_table_with_crops[wide_results_table_with_crops[\"Crop\"] == crop]\n\n        # Select top N models using TRAIN crop sMAPE (NOT test)\n        sorted_models_rand = crop_results[crop_results[\"Split\"] == \"Random Train Crop\"].nsmallest(n, \"sMAPE\")\n        sorted_models_temp = crop_results[crop_results[\"Split\"] == \"Temporal Train Crop\"].nsmallest(n, \"sMAPE\")\n\n        top_model_names_rand = sorted_models_rand[\"Model\"].tolist()\n        top_model_names_temp = sorted_models_temp[\"Model\"].tolist()\n\n        # safer weights (inverse sMAPE with guard)\n        weights_rand = safe_inverse_weights(sorted_models_rand[\"sMAPE\"].tolist())\n        weights_temp = safe_inverse_weights(sorted_models_temp[\"sMAPE\"].tolist())\n\n        X_test_rand_crop = X_test_rand[X_test_rand[\"crop\"] == crop]\n        X_test_temp_crop = X_test_temp[X_test_temp[\"crop\"] == crop]\n        y_test_rand_crop = y_test_rand[X_test_rand[\"crop\"] == crop]\n        y_test_temp_crop = y_test_temp[X_test_temp[\"crop\"] == crop]\n\n        y_pred_ensemble_rand = np.zeros_like(y_test_rand_crop, dtype=float)\n        y_pred_ensemble_temp = np.zeros_like(y_test_temp_crop, dtype=float)\n\n        # Aggregate predictions for Random Split (evaluate on test, OK)\n        for i, model_name in enumerate(top_model_names_rand):\n            model_path = f\"models/{model_name}_random_split\"\n            if os.path.exists(f\"{model_path}.pkl\"):\n                model = load_model(f\"{model_path}.pkl\")\n            elif os.path.exists(f\"{model_path}.keras\"):\n                model = load_model(f\"{model_path}.keras\")\n            else:\n                continue\n\n            y_pred_rand = model.predict(X_test_rand_crop)\n            y_pred_rand = to_1d_pred(y_pred_rand, len(y_test_rand_crop))\n            y_pred_ensemble_rand += weights_rand[i] * y_pred_rand\n\n        # Aggregate predictions for Temporal Split (evaluate on test, OK)\n        for i, model_name in enumerate(top_model_names_temp):\n            model_path = f\"models/{model_name}_temporal_split\"\n            if os.path.exists(f\"{model_path}.pkl\"):\n                model = load_model(f\"{model_path}.pkl\")\n            elif os.path.exists(f\"{model_path}.keras\"):\n                model = load_model(f\"{model_path}.keras\")\n            else:\n                continue\n\n            y_pred_temp = model.predict(X_test_temp_crop)\n            y_pred_temp = to_1d_pred(y_pred_temp, len(y_test_temp_crop))\n            y_pred_ensemble_temp += weights_temp[i] * y_pred_temp\n\n        # Calculate metrics for Random and Temporal Splits (on test, OK)\n        ensemble_rand_metrics = calculate_metrics(y_test_rand_crop, y_pred_ensemble_rand)\n        ensemble_temp_metrics = calculate_metrics(y_test_temp_crop, y_pred_ensemble_temp)\n\n        ensemble_results_crops.append({\n            \"Model\": f\"Ensemble_{n}\",\n            \"Crop\": crop,\n            \"Number of Models\": n,\n            \"Model Names (Random Split)\": \", \".join(top_model_names_rand),\n            \"Model Names (Temporal Split)\": \", \".join(top_model_names_temp),\n            **{f\"{metric}_Random Split Crop\": value for metric, value in ensemble_rand_metrics.items()},\n            **{f\"{metric}_Temporal Split Crop\": value for metric, value in ensemble_temp_metrics.items()},\n        })\n\nensemble_results_crops_df = pd.DataFrame(ensemble_results_crops)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.498642Z","iopub.status.idle":"2025-04-20T13:37:21.498913Z","shell.execute_reply.started":"2025-04-20T13:37:21.498786Z","shell.execute_reply":"2025-04-20T13:37:21.498799Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Importance and Interpretability Analysis\n## Feature Analysis","metadata":{}},{"cell_type":"code","source":"# Set flag to include/exclude temporal models in analysis\ninclude_temporal = True  # Set to False to exclude temporal models\n\n# Filter top models (exclude ensemble models and stacking models) for Random Split\ntop_models_random = results_pivot[\n    ~results_pivot[\"Model\"].str.contains(\"Ensemble\") & ~results_pivot[\"Model\"].str.contains(\"Stacking\")\n]\ntop_models_random = top_models_random.nsmallest(1, \"sMAPE_Random Split\")  # Top 3 for Random Split\n\n# Filter top models for Temporal Split if enabled\nif include_temporal:\n    top_models_temporal = results_pivot[\n        ~results_pivot[\"Model\"].str.contains(\"Ensemble\") & ~results_pivot[\"Model\"].str.contains(\"Stacking\")\n    ]\n    top_models_temporal = top_models_temporal.nsmallest(1, \"sMAPE_Temporal Split\")  # Top 3 for Temporal Split\n\n# Combine the models while maintaining uniqueness\nunique_top_models = set(top_models_random[\"Model\"])\nif include_temporal:\n    unique_top_models.update(top_models_temporal[\"Model\"])\n\n# Placeholder for storing analysis results\nfeature_analysis_results = {}\n\n# Loop through unique models for analysis\nfor model_name in unique_top_models:\n    print(f\"\\nEvaluating {model_name}\")\n    model_path_random = f\"models/{model_name}_random_split.pkl\"\n    model_path_temporal = f\"models/{model_name}_temporal_split.pkl\"\n\n    # Initialize model variables\n    model_random = None\n    model_temporal = None\n\n    # Load models safely\n    try:\n        if os.path.exists(model_path_random):\n            model_random = joblib.load(model_path_random)\n        if include_temporal and os.path.exists(model_path_temporal):\n            model_temporal = joblib.load(model_path_temporal)\n    except Exception as e:\n        print(f\"Error loading model {model_name}: {e}\")\n        continue\n\n    try:\n        # Feature Importance\n        feature_importance_random = (\n            model_random.feature_importances_ if model_random and hasattr(model_random, \"feature_importances_\") else None\n        )\n        feature_importance_temporal = (\n            model_temporal.feature_importances_ if model_temporal and hasattr(model_temporal, \"feature_importances_\") else None\n        ) if include_temporal else None\n\n        # Permutation Importance\n        perm_importance_random = permutation_importance(\n            model_random, X_test_rand, y_test_rand, scoring='neg_mean_absolute_error'\n        ) if model_random else None\n        perm_importance_temporal = (\n            permutation_importance(model_temporal, X_test_temp, y_test_temp, scoring='neg_mean_absolute_error')\n            if include_temporal and model_temporal\n            else None\n        )\n\n        # SHAP Analysis\n        explainer_random = shap.TreeExplainer(model_random) if model_random else None\n        shap_values_random = explainer_random.shap_values(X_test_rand) if explainer_random else None\n\n        explainer_temporal = shap.TreeExplainer(model_temporal) if include_temporal and model_temporal else None\n        shap_values_temporal = explainer_temporal.shap_values(X_test_temp) if explainer_temporal else None\n\n        # Store results\n        feature_analysis_results[model_name] = {\n            \"feature_importance_random\": feature_importance_random,\n            \"feature_importance_temporal\": feature_importance_temporal,\n            \"perm_importance_random\": perm_importance_random.importances_mean if perm_importance_random else None,\n            \"perm_importance_temporal\": perm_importance_temporal.importances_mean if perm_importance_temporal else None,\n            \"shap_values_random\": shap_values_random,\n            \"shap_values_temporal\": shap_values_temporal,\n        }\n    except Exception as e:\n        print(f\"Error analyzing model {model_name}: {e}\")\n        continue","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.499937Z","iopub.status.idle":"2025-04-20T13:37:21.500274Z","shell.execute_reply.started":"2025-04-20T13:37:21.500108Z","shell.execute_reply":"2025-04-20T13:37:21.500124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a directory to save plots if it doesn't already exist\nfeature_analysis_dir = \"feature_analysis\"\nos.makedirs(feature_analysis_dir, exist_ok=True)\n\n# Define the number of top features to display\nTOP_FEATURES = 25\n\n# Loop through top models for visualization\nfor model_name, results in feature_analysis_results.items():\n    # RANDOM SPLIT ANALYSIS\n    if results.get(\"feature_importance_random\") is not None:\n        # Feature Importance Plot (Random Split)\n        sorted_idx_random = np.argsort(-results[\"feature_importance_random\"])[:TOP_FEATURES]\n        feature_names_random = X_train_rand.columns[sorted_idx_random]\n        fig, ax = plt.subplots(figsize=(12, 8))\n        sns.barplot(\n            x=results[\"feature_importance_random\"][sorted_idx_random],\n            y=feature_names_random,\n            ax=ax\n        )\n        ax.set_title(f\"Feature Importance - {model_name} - Random Split\")\n        ax.set_xlabel(\"Importance Score\")\n        ax.set_ylabel(\"Features\")\n        plt.tight_layout()\n        plot_path = os.path.join(feature_analysis_dir, f\"{model_name}_feature_importance_random.png\")\n        plt.savefig(plot_path)\n        plt.show()\n        plt.close()\n\n    if results.get(\"perm_importance_random\") is not None:\n        # Permutation Importance Plot (Random Split)\n        perm_sorted_idx_random = np.argsort(-results[\"perm_importance_random\"])[:TOP_FEATURES]\n        feature_names_perm_random = X_train_rand.columns[perm_sorted_idx_random]\n        fig, ax = plt.subplots(figsize=(12, 8))\n        sns.barplot(\n            x=results[\"perm_importance_random\"][perm_sorted_idx_random],\n            y=feature_names_perm_random,\n            ax=ax\n        )\n        ax.set_title(f\"Permutation Importance - {model_name} - Random Split\")\n        ax.set_xlabel(\"Importance Score\")\n        ax.set_ylabel(\"Features\")\n        plt.tight_layout()\n        plot_path = os.path.join(feature_analysis_dir, f\"{model_name}_permutation_importance_random.png\")\n        plt.savefig(plot_path)\n        plt.show()\n        plt.close()\n\n    if results.get(\"shap_values_random\") is not None:\n        # SHAP Summary Plot (Random Split)\n        fig, ax = plt.subplots(figsize=(12, 8))\n        shap.summary_plot(\n            results[\"shap_values_random\"], X_test_rand, max_display=TOP_FEATURES, show=False\n        )\n        plt.title(f\"SHAP Summary - {model_name} - Random Split\")\n        plot_path = os.path.join(feature_analysis_dir, f\"{model_name}_shap_random.png\")\n        plt.savefig(plot_path)\n        plt.show()\n        plt.close()\n\n    # TEMPORAL SPLIT ANALYSIS (if temporal models are enabled)\n    if include_temporal:\n        if results.get(\"feature_importance_temporal\") is not None:\n            # Feature Importance Plot (Temporal Split)\n            sorted_idx_temporal = np.argsort(-results[\"feature_importance_temporal\"])[:TOP_FEATURES]\n            feature_names_temporal = X_train_temp.columns[sorted_idx_temporal]\n            fig, ax = plt.subplots(figsize=(12, 8))\n            sns.barplot(\n                x=results[\"feature_importance_temporal\"][sorted_idx_temporal],\n                y=feature_names_temporal,\n                ax=ax\n            )\n            ax.set_title(f\"Feature Importance - {model_name} - Temporal Split\")\n            ax.set_xlabel(\"Importance Score\")\n            ax.set_ylabel(\"Features\")\n            plt.tight_layout()\n            plot_path = os.path.join(feature_analysis_dir, f\"{model_name}_feature_importance_temporal.png\")\n            plt.savefig(plot_path)\n            plt.show()\n            plt.close()\n\n        if results.get(\"perm_importance_temporal\") is not None:\n            # Permutation Importance Plot (Temporal Split)\n            perm_sorted_idx_temporal = np.argsort(-results[\"perm_importance_temporal\"])[:TOP_FEATURES]\n            feature_names_perm_temporal = X_train_temp.columns[perm_sorted_idx_temporal]\n            fig, ax = plt.subplots(figsize=(12, 8))\n            sns.barplot(\n                x=results[\"perm_importance_temporal\"][perm_sorted_idx_temporal],\n                y=feature_names_perm_temporal,\n                ax=ax\n            )\n            ax.set_title(f\"Permutation Importance - {model_name} - Temporal Split\")\n            ax.set_xlabel(\"Importance Score\")\n            ax.set_ylabel(\"Features\")\n            plt.tight_layout()\n            plot_path = os.path.join(feature_analysis_dir, f\"{model_name}_permutation_importance_temporal.png\")\n            plt.savefig(plot_path)\n            plt.show()\n            plt.close()\n\n        if results.get(\"shap_values_temporal\") is not None:\n            # SHAP Summary Plot (Temporal Split)\n            fig, ax = plt.subplots(figsize=(12, 8))\n            shap.summary_plot(\n                results[\"shap_values_temporal\"], X_test_temp, max_display=TOP_FEATURES, show=False\n            )\n            plt.title(f\"SHAP Summary - {model_name} - Temporal Split\")\n            plot_path = os.path.join(feature_analysis_dir, f\"{model_name}_shap_temporal.png\")\n            plt.savefig(plot_path)\n            plt.show()\n            plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare a list to hold feature importance data for all models\nfeature_analysis_data = []\n\n# Loop through each model and extract feature importance results\nfor model_name, results in feature_analysis_results.items():\n    # Random Split Feature Importance\n    for i, feature_name in enumerate(X_train_rand.columns):\n        feature_analysis_data.append({\n            \"Model\": model_name,\n            \"Split\": \"Random\",\n            \"Feature\": feature_name,\n            \"Importance\": results[\"feature_importance_random\"][i]\n        })\n    \n    # Temporal Split Feature Importance\n    for i, feature_name in enumerate(X_train_temp.columns):\n        feature_analysis_data.append({\n            \"Model\": model_name,\n            \"Split\": \"Temporal\",\n            \"Feature\": feature_name,\n            \"Importance\": results[\"feature_importance_temporal\"][i]\n        })\n\n# Convert the list of dictionaries to a DataFrame\nfeature_analysis_df = pd.DataFrame(feature_analysis_data)\nfeature_analysis_df.sort_values(by=\"Importance\", ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.502394Z","iopub.status.idle":"2025-04-20T13:37:21.502683Z","shell.execute_reply.started":"2025-04-20T13:37:21.502538Z","shell.execute_reply":"2025-04-20T13:37:21.502566Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Random-Temporal Importance Comparison","metadata":{}},{"cell_type":"code","source":"# Calculate average importance per feature for each split\nrandom_split_importance = feature_analysis_df[feature_analysis_df['Split'] == 'Random'].groupby('Feature')['Importance'].mean()\ntemporal_split_importance = feature_analysis_df[feature_analysis_df['Split'] == 'Temporal'].groupby('Feature')['Importance'].mean()\n\n# Combine into a single DataFrame for comparison\nimportance_comparison = pd.DataFrame({\n    'Feature': random_split_importance.index,\n    'Random Importance': random_split_importance.values,\n    'Temporal Importance': temporal_split_importance.reindex(random_split_importance.index).values\n})\n\n# Calculate the difference and rank features by the difference\nimportance_comparison['Difference'] = importance_comparison['Random Importance'] - importance_comparison['Temporal Importance']\nimportance_comparison['Absolute Difference'] = importance_comparison['Difference'].abs()\n\n# Sort by absolute difference for analysis\nimportance_comparison = importance_comparison.sort_values(by='Absolute Difference', ascending=False)\nimportance_comparison.sort_values(by=\"Absolute Difference\", ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:37:21.504099Z","iopub.status.idle":"2025-04-20T13:37:21.504318Z","shell.execute_reply.started":"2025-04-20T13:37:21.504213Z","shell.execute_reply":"2025-04-20T13:37:21.504222Z"}},"outputs":[],"execution_count":null}]}