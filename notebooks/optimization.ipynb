{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":220006059,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":29763.042812,"end_time":"2025-02-14T07:48:12.970343","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-13T23:32:09.927531","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"746a10c7","cell_type":"code","source":"import os\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport gc\nimport random\n\nfrom scipy import stats\nfrom scipy.spatial.distance import cosine, mahalanobis\nfrom scipy.stats import ks_2samp, skew, kurtosis, entropy, f_oneway, norm\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.svm import SVR\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Multiply, Add, BatchNormalization, LayerNormalization, MultiHeadAttention, Reshape\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.utils import plot_model\n\nimport pyswarm\nfrom skopt import gp_minimize\nfrom skopt.space import Real\nfrom pyswarm import pso\nfrom scipy.stats import qmc\nfrom scipy.optimize import minimize\nfrom scipy.optimize import dual_annealing\nfrom scipy.optimize import differential_evolution as genetic_algorithm\nfrom scipy.interpolate import Rbf\nfrom scipy.spatial import Delaunay\nfrom scipy.ndimage import gaussian_filter\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nfrom matplotlib.colors import Normalize, TwoSlopeNorm\n\ngc.enable()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":25.577046,"end_time":"2025-02-13T23:32:37.743196","exception":false,"start_time":"2025-02-13T23:32:12.166150","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"b481c576","cell_type":"code","source":"seed = 42\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ntf.random.set_seed(seed)","metadata":{"papermill":{"duration":0.019227,"end_time":"2025-02-13T23:32:37.774313","exception":false,"start_time":"2025-02-13T23:32:37.755086","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"29f83d78","cell_type":"code","source":"# Create a directory to save plots if it doesn't already exist\noptimization_dir = \"optimization\"\nos.makedirs(optimization_dir, exist_ok=True)","metadata":{"papermill":{"duration":0.087085,"end_time":"2025-02-13T23:59:27.225849","exception":false,"start_time":"2025-02-13T23:59:27.138764","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"049ff6bc","cell_type":"code","source":"# Extract the top ensembles for each crop based on lowest MAPE_Random Split Crop\ntop_ensembles = ensemble_results_crops_df.loc[\n    ensemble_results_crops_df.groupby('Crop')['MAPE_Random Split Crop'].idxmin()\n]\n\n# Parse the model names and compute weights based on individual MAPE values\ntop_ensemble_models = {}\nfor _, row in top_ensembles.iterrows():\n    crop = row['Crop']\n    model_names = row['Model Names (Random Split)'].split(', ')\n\n    # Retrieve individual MAPE values for the models\n    mape_values = []\n    for model_name in model_names:\n        mape = wide_results_table_with_crops[\n            (wide_results_table_with_crops['Model'] == model_name) &\n            (wide_results_table_with_crops['Crop'] == crop) &\n            (wide_results_table_with_crops['Split'] == 'Random Split Crop')\n        ]['MAPE'].values\n        if len(mape) > 0:\n            mape_values.append(float(mape[0]))\n        else:\n            print(f\"Warning: MAPE not found for model {model_name} in crop {crop}\")\n            mape_values.append(float('inf'))  # Assign a very high value if MAPE is missing\n\n    # Calculate weights based on the corrected MAPE values\n    weights = np.array([1 / mape for mape in mape_values])\n    weights /= weights.sum()  # Normalize weights\n\n    top_ensemble_models[crop] = {\n        'models': model_names,\n        'weights': weights\n    }\n\n# Prepare the results as a DataFrame for display\ntop_ensemble_df = pd.DataFrame([\n    {\n        'Crop': crop,\n        'Models': ', '.join(info['models']),\n        'Weights': ', '.join(map(str, info['weights']))\n    }\n    for crop, info in top_ensemble_models.items()\n])","metadata":{"papermill":{"duration":0.103,"end_time":"2025-02-13T23:59:27.410232","exception":false,"start_time":"2025-02-13T23:59:27.307232","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a5b9d989","cell_type":"code","source":"# Compute adaptive environmental impact scaling factor (lambda_env)\ndef compute_lambda_env(X, Y):\n    # Computes an adaptive lambda_env based on soil properties, nutrient efficiency, and climate zone.\n    lambda_0 = 1  # Base penalty\n\n    # Soil depletion factor\n    R_soil = (\n        max(0, (6.5 - X['soil_ph'].mean())) / 10 +\n        max(0, (2 - X['organic_matter_percent'].mean())) / 5 +\n        max(0, (X['electrical_conductivity'].mean() - 0.5)) / 10\n    )\n\n    # Nutrient use efficiency factor\n    NUE = X['npk_nitrogen'].mean() / max(1, Y.mean())  # Avoid division by zero\n    PUE = X['npk_phosphorus_p2o5'].mean() / max(1, Y.mean())\n    KUE = X['npk_potassium_k2o'].mean() / max(1, Y.mean())\n    R_nutrient = NUE + PUE + KUE\n\n    # Climate zone impact\n    climate_zone_map = {0: 0.05, 1: 0.1, 2: 0.15, 3: 0.12}  # Mapped impact\n    climate_zone_avg = int(X['climate_zone'].mean())  # Convert to int\n    R_environment = climate_zone_map.get(climate_zone_avg, 0.1)  # Default 0.1 if missing\n\n    # Compute adaptive lambda_env\n    return lambda_0 * (1 + R_soil + R_nutrient + R_environment)\n\n# Placeholder for optimization results\noptimization_results = []\n\n# Define bounds for NPK values\nnpk_bounds = [\n    (X['npk_nitrogen'].min(), X['npk_nitrogen'].max()),\n    (X['npk_phosphorus_p2o5'].min(), X['npk_phosphorus_p2o5'].max()),\n    (X['npk_potassium_k2o'].min(), X['npk_potassium_k2o'].max())\n]\n\n# Define the yield predictor\ndef predict_yield(params, crop, X, top_ensemble_models):\n    # Predicts the yield for a given crop using the ensemble of models and their weights.\n    npk_nitrogen, npk_phosphorus_p2o5, npk_potassium_k2o = params\n    X['npk_nitrogen'] = npk_nitrogen\n    X['npk_phosphorus_p2o5'] = npk_phosphorus_p2o5\n    X['npk_potassium_k2o'] = npk_potassium_k2o\n\n    # Get ensemble models and weights for the crop\n    ensemble_info = top_ensemble_models[crop]\n    predicted_yield = 0\n\n    for model_name, weight in zip(ensemble_info['models'], ensemble_info['weights']):\n        model_path = f\"models/{model_name}_random_split\"\n        if os.path.exists(f\"{model_path}.pkl\"):\n            model = load_model(f\"{model_path}.pkl\")\n        elif os.path.exists(f\"{model_path}.keras\"):\n            model = load_model(f\"{model_path}.keras\")\n        else:\n            continue\n        \n        # Use the model to predict\n        y_pred = model.predict(X)\n        predicted_yield += weight * y_pred.mean()  # Weighted prediction (scalar)\n\n    return predicted_yield\n\n# Define the objective function\ndef objective_function(params, crop, X, Y, top_ensemble_models):\n    # Objective function for optimization.\n    lambda_reg = compute_lambda_env(X, Y)  # Dynamically compute lambda_reg\n\n    npk_nitrogen, npk_phosphorus_p2o5, npk_potassium_k2o = params\n    X['npk_nitrogen'] = npk_nitrogen\n    X['npk_phosphorus_p2o5'] = npk_phosphorus_p2o5\n    X['npk_potassium_k2o'] = npk_potassium_k2o\n\n    # Extract ensemble information for the given crop\n    ensemble_info = top_ensemble_models[crop]\n\n    # Weighted prediction using ensemble models\n    predicted_yield = 0\n    for model_name, weight in zip(ensemble_info['models'], ensemble_info['weights']):\n        model_path = f\"models/{model_name}_random_split\"\n        if os.path.exists(f\"{model_path}.pkl\"):\n            model = load_model(f\"{model_path}.pkl\")\n        elif os.path.exists(f\"{model_path}.keras\"):\n            model = load_model(f\"{model_path}.keras\")\n        else:\n            continue\n\n        # Use model to predict yield\n        y_pred = model.predict(X)\n        predicted_yield += weight * y_pred.mean()  # Ensure scalar aggregation\n\n    # Total NPK applied\n    total_npk = npk_nitrogen + npk_phosphorus_p2o5 + npk_potassium_k2o\n\n    # Return scalar value for the optimization\n    return -(predicted_yield - lambda_reg * total_npk)\n\n# Define a helper function to calculate metrics\ndef calculate_metrics(params, crop, X, Y):\n    lambda_reg = compute_lambda_env(X, Y)\n    optimized_n, optimized_p, optimized_k = params\n    total_npk = optimized_n + optimized_p + optimized_k\n\n    # Predict yield using the optimized NPK values\n    predicted_yield = predict_yield(params, crop, X, top_ensemble_models)\n\n    # Calculate metrics\n    yield_improvement = predicted_yield - baseline_yield\n    nutrient_efficiency = predicted_yield / total_npk if total_npk > 0 else 0\n    environmental_impact = lambda_reg * total_npk\n    \n    return lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact\n\n# Define Bayesian Optimization\ndef bayesian_optimizer(crop, X, Y, top_ensemble_models):\n    # Step 1: Bayesian Optimization (Faster)\n    bayesian_result = gp_minimize(\n        func=lambda params: objective_function(params, crop, X, Y, top_ensemble_models),\n        dimensions=npk_bounds,\n        n_calls=200,\n        random_state=42,\n        n_jobs=-1  # Parallel execution\n    )\n\n    return bayesian_result\n\n# Define Bayesian-Evolutionary Hybrid\ndef bayesian_evolutionary_hybrid(crop, X, Y, top_ensemble_models):\n    # Perform Bayesian Optimization first\n    bayesian_result = gp_minimize(\n        func=lambda params: objective_function(params, crop, X, Y, top_ensemble_models),\n        dimensions=npk_bounds,\n        n_calls=200,\n        random_state=42,\n        n_jobs=-1\n    )\n\n    # Generate an improved initial population using Latin Hypercube Sampling (LHS)\n    sampler = qmc.LatinHypercube(d=len(npk_bounds))\n    initial_population = qmc.scale(sampler.random(n=5), [b[0] for b in npk_bounds], [b[1] for b in npk_bounds])\n    initial_population = initial_population.tolist()\n    \n    # Include the best result from Bayesian Optimization\n    initial_population.append(bayesian_result.x)\n\n    # Convert to NumPy array\n    initial_population = np.array(initial_population)\n\n    # Apply Genetic Algorithm with optimized parameters\n    genetic_result = genetic_algorithm(\n        func=lambda params: objective_function(params, crop, X, Y, top_ensemble_models),\n        bounds=npk_bounds,\n        strategy='best1bin',  # Efficient differential evolution strategy\n        init=initial_population,\n        popsize=10,  # Increase diversity instead of excessive iterations\n        maxiter=500, \n        mutation=(0.5, 1),  # Adaptive mutation range\n        recombination=0.7  # Slightly increased for better exploration\n    )\n\n    return genetic_result\n\n# Define Gradient-Assisted Evolutionary Algorithm\ndef gradient_assisted_evolutionary(crop, X, Y, top_ensemble_models):\n    # Perform Genetic Algorithm first\n    genetic_result = genetic_algorithm(\n        func=lambda params: objective_function(params, crop, X, Y, top_ensemble_models),\n        bounds=npk_bounds,\n        strategy='best1bin',\n        popsize=15,\n        maxiter=1000\n    )\n\n    # Use the output as the starting point for Gradient Descent\n    gradient_result = minimize(\n        fun=objective_function,\n        x0=genetic_result.x,\n        args=(crop, X, Y, top_ensemble_models),\n        bounds=npk_bounds,\n        method='L-BFGS-B'\n    )\n    return gradient_result\n\n# Define Adaptive Differential Evolution\ndef adaptive_differential_evolution(crop, X, Y, top_ensemble_models):\n    # Adjust mutation and crossover strategies dynamically\n    adaptive_result = genetic_algorithm(\n        func=lambda params: objective_function(params, crop, X, Y, top_ensemble_models),\n        bounds=npk_bounds,\n        strategy='randtobest1bin',  # Adaptive strategy\n        mutation=(0.5, 1),          # Mutation bounds\n        recombination=0.9,         # Higher recombination rate\n        maxiter=1000\n    )\n    return adaptive_result\n\n# Define Policy-Based Optimization\ndef policy_based(crop, X, Y, top_ensemble_models, episodes=3000, initial_lr=0.1, exploration_scale=10.0, decay_factor=0.9):\n    policy = np.random.uniform([bound[0] for bound in npk_bounds], [bound[1] for bound in npk_bounds]).astype(np.float64)\n    best_reward = -np.inf\n    best_params = None\n\n    for episode in range(episodes):\n        # Adaptive exploration\n        current_exploration = exploration_scale * (decay_factor ** episode)\n        action = policy + np.random.uniform(-current_exploration, current_exploration, size=len(npk_bounds))\n\n        # Clip action to within bounds\n        action = np.clip(action, [bound[0] for bound in npk_bounds], [bound[1] for bound in npk_bounds])\n\n        # Evaluate reward\n        reward = -objective_function(action, crop, X, Y, top_ensemble_models)\n\n        # Update policy based on reward\n        if reward > best_reward:\n            best_reward = reward\n            best_params = action\n\n        policy += initial_lr * (reward - best_reward) * (action - policy)\n\n    return best_params, best_reward\n\n# Define Q-Learning Optimization\ndef q_learning(crop, X, Y, top_ensemble_models, episodes=3000, gamma=0.9, exploration_scale=10.0, decay_factor=0.9):\n    Q = np.random.uniform([bound[0] for bound in npk_bounds], [bound[1] for bound in npk_bounds]).astype(np.float64)\n    best_reward = -np.inf\n    best_params = None\n\n    for episode in range(episodes):\n        # Adaptive exploration\n        current_exploration = exploration_scale * (decay_factor ** episode)\n        current_exploration = max(current_exploration, 1.0)  # Minimum exploration scale\n        action = Q + np.random.uniform(-current_exploration, current_exploration, size=len(npk_bounds))\n\n        # Clip action to within bounds\n        action = np.clip(action, [bound[0] for bound in npk_bounds], [bound[1] for bound in npk_bounds])\n\n        # Validate action\n        if np.any(np.isnan(action)):\n            print(f\"Warning: NaN detected in action at episode {episode}. Resetting action.\")\n            action = Q\n\n        # Evaluate reward\n        reward = -objective_function(action, crop, X, Y, top_ensemble_models)\n        if np.isnan(reward):\n            print(f\"Warning: NaN detected in reward at episode {episode}. Assigning penalty.\")\n            reward = -1e6  # Penalize invalid rewards\n\n        # Update Q-values using temporal difference\n        Q += gamma * (reward - best_reward) * (action - Q)\n        Q = np.clip(Q, [bound[0] for bound in npk_bounds], [bound[1] for bound in npk_bounds])  # Regularize Q\n\n        # Update best parameters\n        if reward > best_reward:\n            best_reward = reward\n            best_params = action\n\n        # Debugging\n        # print(f\"Episode {episode}: Q={Q}, action={action}, reward={reward}\")\n\n    return best_params, best_reward","metadata":{"papermill":{"duration":0.245441,"end_time":"2025-02-13T23:59:27.901964","exception":false,"start_time":"2025-02-13T23:59:27.656523","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f2e84d66","cell_type":"code","source":"# Main optimization loop\nfor crop in top_ensemble_models.keys():\n    print(f\"Loop {crop + 1}\")\n    # Filter X and y for the specific crop\n    X_crop = X_test_rand[X_test_rand['crop'] == crop].copy()\n    y_crop = y_test_rand[X_crop.index]  # Align y with the subset X_crop\n\n    # Calculate the baseline yield dynamically\n    baseline_yield = y_crop.median()\n\n    # Gradient Descent\n    print('Running Gradient Descent')\n    gradient_result = minimize(\n        fun=objective_function,\n        x0=[100, 50, 50],\n        args=(crop, X_crop, y_crop, top_ensemble_models),\n        bounds=npk_bounds,\n        method='L-BFGS-B'\n    )\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        gradient_result.x, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Gradient Descent',\n        'Optimized N': gradient_result.x[0],\n        'Optimized P': gradient_result.x[1],\n        'Optimized K': gradient_result.x[2],\n        'Objective Value': -gradient_result.fun,\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\n    # Genetic Algorithm\n    print('Running Genetic Algorithm')\n    genetic_result = genetic_algorithm(\n        func=lambda params: objective_function(params, crop, X_crop, y_crop, top_ensemble_models),\n        bounds=npk_bounds,\n        strategy='best1bin',\n        maxiter=1000\n    )\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        genetic_result.x, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Genetic Algorithm',\n        'Optimized N': genetic_result.x[0],\n        'Optimized P': genetic_result.x[1],\n        'Optimized K': genetic_result.x[2],\n        'Objective Value': -genetic_result.fun,\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\n    # Particle Swarm Optimization\n    print('Running Particle Swarm Optimization')\n    pso_result = pso(\n        func=lambda params: objective_function(params, crop, X_crop, y_crop, top_ensemble_models),\n        lb=[bound[0] for bound in npk_bounds],\n        ub=[bound[1] for bound in npk_bounds],\n        swarmsize=30, # Increased from 15 to 30\n        maxiter=1000\n    )\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        pso_result[0], crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Particle Swarm Optimization',\n        'Optimized N': pso_result[0][0],\n        'Optimized P': pso_result[0][1],\n        'Optimized K': pso_result[0][2],\n        'Objective Value': -pso_result[1],\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\n    # Simulated Annealing\n    print('Running Simulated Annealing')\n    simulated_result = dual_annealing(\n        func=lambda params: objective_function(params, crop, X_crop, y_crop, top_ensemble_models),\n        bounds=npk_bounds,\n        maxiter=1000\n    )\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        simulated_result.x, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Simulated Annealing',\n        'Optimized N': simulated_result.x[0],\n        'Optimized P': simulated_result.x[1],\n        'Optimized K': simulated_result.x[2],\n        'Objective Value': -simulated_result.fun,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\n    # Bayesian Optimization\n    print('Running Bayesian Optimization')\n    bayesian_result = bayesian_optimizer(crop, X_crop, y_crop, top_ensemble_models)\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        bayesian_result.x, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Bayesian Optimization',\n        'Optimized N': bayesian_result.x[0],\n        'Optimized P': bayesian_result.x[1],\n        'Optimized K': bayesian_result.x[2],\n        'Objective Value': -bayesian_result.fun,\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n    \n    # Bayesian-Evolutionary Hybrid\n    print('Running Bayesian-Evolutionary Hybrid')\n    hybrid_result = bayesian_evolutionary_hybrid(crop, X_crop, y_crop, top_ensemble_models)\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        hybrid_result.x, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Bayesian-Evolutionary Hybrid',\n        'Optimized N': hybrid_result.x[0],\n        'Optimized P': hybrid_result.x[1],\n        'Optimized K': hybrid_result.x[2],\n        'Objective Value': -hybrid_result.fun,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\n    # Gradient-Assisted Evolutionary Algorithm\n    print('Running Gradient-Assisted Evolutionary Algorithm')\n    gradient_assisted_result = gradient_assisted_evolutionary(crop, X_crop, y_crop, top_ensemble_models)\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        gradient_assisted_result.x, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Gradient-Assisted Evolutionary',\n        'Optimized N': gradient_assisted_result.x[0],\n        'Optimized P': gradient_assisted_result.x[1],\n        'Optimized K': gradient_assisted_result.x[2],\n        'Objective Value': -gradient_assisted_result.fun,\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\n    # Adaptive Differential Evolution\n    print('Running Adaptive Differential Evolution')\n    adaptive_result = adaptive_differential_evolution(crop, X_crop, y_crop, top_ensemble_models)\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        adaptive_result.x, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Adaptive Differential Evolution',\n        'Optimized N': adaptive_result.x[0],\n        'Optimized P': adaptive_result.x[1],\n        'Optimized K': adaptive_result.x[2],\n        'Objective Value': -adaptive_result.fun,\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\n    # Policy-Based Optimization\n    print('Running Policy-Based Optimization')\n    policy_params, policy_reward = policy_based(crop, X_crop, y_crop, top_ensemble_models)\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        policy_params, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Policy-Based Optimization',\n        'Optimized N': policy_params[0],\n        'Optimized P': policy_params[1],\n        'Optimized K': policy_params[2],\n        'Objective Value': policy_reward,\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n    \n    # Q-Learning Optimization\n    print('Running Q-Learning Optimization')\n    q_params, q_reward = q_learning(crop, X_crop, y_crop, top_ensemble_models)\n    lambda_reg, predicted_yield, yield_improvement, nutrient_efficiency, environmental_impact = calculate_metrics(\n        q_params, crop, X_crop, y_crop\n    )\n    optimization_results.append({\n        'Crop': crop,\n        'Method': 'Q-Learning Optimization',\n        'Optimized N': q_params[0],\n        'Optimized P': q_params[1],\n        'Optimized K': q_params[2],\n        'Objective Value': q_reward,\n        'Lambda Regularization': lambda_reg,\n        'Yield Improvement': yield_improvement,\n        'Nutrient Efficiency': nutrient_efficiency,\n        'Environmental Impact': environmental_impact\n    })\n\noptimization_results_df = pd.DataFrame(optimization_results)","metadata":{"papermill":{"duration":28109.347994,"end_time":"2025-02-14T07:47:57.330233","exception":false,"start_time":"2025-02-13T23:59:27.982239","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"d2f4e4fb","cell_type":"code","source":"optimization_results_df","metadata":{"papermill":{"duration":0.109305,"end_time":"2025-02-14T07:47:57.529630","exception":false,"start_time":"2025-02-14T07:47:57.420325","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a882ad5f","cell_type":"code","source":"# Group by 'Method' and sum the columns\noptimization_method_sums_df = optimization_results_df.groupby(\"Method\").sum(numeric_only=True).reset_index()\noptimization_method_sums_df[['Method', 'Objective Value', 'Yield Improvement', 'Nutrient Efficiency', 'Environmental Impact']].sort_values(by=\"Objective Value\", ascending=False)","metadata":{"papermill":{"duration":0.111711,"end_time":"2025-02-14T07:47:57.727449","exception":false,"start_time":"2025-02-14T07:47:57.615738","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"baa34606","cell_type":"code","source":"# Normalize and format Method names in title case\noptimization_results_df['Method'] = optimization_results_df['Method'].str.strip().str.title()\naverage_values = (\n    optimization_results_df.groupby('Method', as_index=False)['Objective Value']\n    .mean()\n    .sort_values(by='Method')  # Sort explicitly by Method\n    .reset_index(drop=True)\n)\naverage_values.rename(columns={'Objective Value': 'Average Objective Value'}, inplace=True)\naverage_values['Method'] = average_values['Method'].str.strip().str.title()\n\n\n# Extract unique methods in the order of the bar plot\nunique_methods = optimization_results_df['Method'].unique()\n\n# Check if all methods are aligned\nif not all(average_values['Method'].values == unique_methods):\n    print(\"Mismatch detected! Correcting alignment explicitly...\")\n    average_values = average_values.set_index('Method').reindex(unique_methods).reset_index()\n\n# Plot the bar chart\nplt.figure(figsize=(12, 7))\nsns.barplot(x='Method', y='Objective Value', hue='Crop', data=optimization_results_df, ci=None)\nplt.title('Objective Value Across Methods and Crops', fontsize=16)\nplt.xlabel('Optimization Method', fontsize=12)\nplt.ylabel('Objective Value', fontsize=12)\nplt.xticks(rotation=45, fontsize=10, ha='right')\nplt.yticks(fontsize=10)\nplt.legend(bbox_to_anchor=(1.05, 1), title='Crop', loc='upper left', fontsize=10)\n\n# Overlay the average values as small black rhombuses and connect them with a line\nx_coords = range(len(unique_methods))  # Align with bar positions\nplt.plot(x_coords, average_values['Average Objective Value'], color='black', linestyle='-', linewidth=1, label='Average Objective Value')\nplt.scatter(x_coords, average_values['Average Objective Value'], color='black', marker='D', s=40)\n\n# Add a legend for the averages\nplt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', fontsize=10)\n\n# Save the plot\nplot_path = os.path.join(optimization_dir, \"objective-value-across-methods-and-crops-with-averages.png\")\nplt.tight_layout()\nplt.savefig(plot_path, dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"papermill":{"duration":0.926547,"end_time":"2025-02-14T07:48:01.219463","exception":false,"start_time":"2025-02-14T07:48:00.292916","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"3ff3f1cc","cell_type":"code","source":"# Normalize and format Method names in title case\noptimization_results_df['Method'] = optimization_results_df['Method'].str.strip().str.title()\n\naverage_yield_improvement = (\n    optimization_results_df.groupby('Method', as_index=False)['Yield Improvement']\n    .mean()\n    .sort_values(by='Method')  # Sort explicitly by Method\n    .reset_index(drop=True)\n)\naverage_yield_improvement.rename(columns={'Yield Improvement': 'Average Yield Improvement'}, inplace=True)\n\naverage_yield_improvement['Method'] = average_yield_improvement['Method'].str.strip().str.title()\n\n# Extract unique methods in the order of the bar plot\nunique_methods = optimization_results_df['Method'].unique()\n\n# Check if all methods are aligned\nif not all(average_yield_improvement['Method'].values == unique_methods):\n    print(\"Mismatch detected! Correcting alignment explicitly...\")\n    average_yield_improvement = average_yield_improvement.set_index('Method').reindex(unique_methods).reset_index()\n\n# Plot the bar chart\nplt.figure(figsize=(12, 7))\nsns.barplot(x='Method', y='Yield Improvement', hue='Crop', data=optimization_results_df, ci=None)\nplt.title('Yield Improvement Across Methods and Crops', fontsize=16)\nplt.xlabel('Optimization Method', fontsize=12)\nplt.ylabel('Yield Improvement (kg/ha)', fontsize=12)\nplt.xticks(rotation=45, fontsize=10, ha='right')\nplt.yticks(fontsize=10)\nplt.legend(bbox_to_anchor=(1.05, 1), title='Crop', loc='upper left', fontsize=10)\n\n# Overlay the average values as small black rhombuses and connect them with a line\nx_coords = range(len(unique_methods))  # Align with bar positions\nplt.plot(\n    x_coords,\n    average_yield_improvement['Average Yield Improvement'],\n    color='black',\n    linestyle='-',\n    linewidth=1,\n    label='Average Yield Improvement',\n)\nplt.scatter(\n    x_coords,\n    average_yield_improvement['Average Yield Improvement'],\n    color='black',\n    marker='D',\n    s=40,\n)\n\n# Add a legend for the averages\nplt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', fontsize=10)\n\n# Save the plot\nplot_path = os.path.join(optimization_dir, \"yield-improvement-across-methods-and-crops-with-averages.png\")\nplt.tight_layout()\nplt.savefig(plot_path, dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"papermill":{"duration":0.925955,"end_time":"2025-02-14T07:48:02.247574","exception":false,"start_time":"2025-02-14T07:48:01.321619","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"64ecb937","cell_type":"code","source":"# Normalize and format Method names in title case\noptimization_results_df['Method'] = optimization_results_df['Method'].str.strip().str.title()\n\naverage_efficiency = (\n    optimization_results_df.groupby('Method', as_index=False)['Nutrient Efficiency']\n    .mean()\n    .sort_values(by='Method')  # Sort explicitly by Method\n    .reset_index(drop=True)\n)\naverage_efficiency.rename(columns={'Nutrient Efficiency': 'Average Nutrient Efficiency'}, inplace=True)\naverage_efficiency['Method'] = average_efficiency['Method'].str.strip().str.title()\n\n# Extract unique methods in the order of the bar plot\nunique_methods = optimization_results_df['Method'].unique()\n\n# Check if all methods are aligned\nif not all(average_efficiency['Method'].values == unique_methods):\n    print(\"Mismatch detected! Correcting alignment explicitly...\")\n    average_efficiency = average_efficiency.set_index('Method').reindex(unique_methods).reset_index()\n\n# Plot the bar chart\nplt.figure(figsize=(12, 7))\nsns.barplot(x='Method', y='Nutrient Efficiency', hue='Crop', data=optimization_results_df, ci=None)\nplt.title('Nutrient Efficiency Across Methods and Crops', fontsize=16)\nplt.xlabel('Optimization Method', fontsize=12)\nplt.ylabel('Nutrient Efficiency (Yield/Total NPK)', fontsize=12)\nplt.xticks(rotation=45, fontsize=10, ha='right')\nplt.yticks(fontsize=10)\nplt.legend(bbox_to_anchor=(1.05, 1), title='Crop', loc='upper left', fontsize=10)\n\n# Overlay the average values as small black rhombuses and connect them with a line\nx_coords = range(len(unique_methods))  # Align with bar positions\nplt.plot(\n    x_coords,\n    average_efficiency['Average Nutrient Efficiency'],\n    color='black',\n    linestyle='-',\n    linewidth=1,\n    label='Average Nutrient Efficiency',\n)\nplt.scatter(\n    x_coords,\n    average_efficiency['Average Nutrient Efficiency'],\n    color='black',\n    marker='D',\n    s=40,\n)\n\n# Add a legend for the averages\nplt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', fontsize=10)\n\n# Save the plot\nplot_path = os.path.join(optimization_dir, \"nutrient-efficiency-across-methods-and-crops-with-averages.png\")\nplt.tight_layout()\nplt.savefig(plot_path, dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"papermill":{"duration":0.958247,"end_time":"2025-02-14T07:48:03.308674","exception":false,"start_time":"2025-02-14T07:48:02.350427","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"92f5f2cc","cell_type":"code","source":"# Normalize and format Method names in title case\noptimization_results_df['Method'] = optimization_results_df['Method'].str.strip().str.title()\n\n# Calculate the average Environmental Impact for each method\naverage_environmental_impact = (\n    optimization_results_df.groupby('Method', as_index=False)['Environmental Impact']\n    .mean()\n    .sort_values(by='Method')  # Sort explicitly by Method\n    .reset_index(drop=True)\n)\naverage_environmental_impact.rename(columns={'Environmental Impact': 'Average Environmental Impact'}, inplace=True)\naverage_environmental_impact['Method'] = average_environmental_impact['Method'].str.strip().str.title()\n\n# Extract unique methods in the order of the bar plot\nunique_methods = optimization_results_df['Method'].unique()\n\n# Check if all methods are aligned\nif not all(average_environmental_impact['Method'].values == unique_methods):\n    print(\"Mismatch detected! Correcting alignment explicitly...\")\n    average_environmental_impact = average_environmental_impact.set_index('Method').reindex(unique_methods).reset_index()\n\n# Plot the bar chart\nplt.figure(figsize=(12, 7))\nsns.barplot(x='Method', y='Environmental Impact', hue='Crop', data=optimization_results_df, ci=None)\nplt.title('Environmental Impact Across Methods and Crops', fontsize=16)\nplt.xlabel('Optimization Method', fontsize=12)\nplt.ylabel('Environmental Impact (Total NPK)', fontsize=12)\nplt.xticks(rotation=45, fontsize=10, ha='right')\nplt.yticks(fontsize=10)\nplt.legend(bbox_to_anchor=(1.05, 1), title='Crop', loc='upper left', fontsize=10)\n\n# Overlay the average values as small black rhombuses and connect them with a line\nx_coords = range(len(unique_methods))  # Align with bar positions\nplt.plot(\n    x_coords,\n    average_environmental_impact['Average Environmental Impact'],\n    color='black',\n    linestyle='-',\n    linewidth=1,\n    label='Average Environmental Impact',\n)\nplt.scatter(\n    x_coords,\n    average_environmental_impact['Average Environmental Impact'],\n    color='black',\n    marker='D',\n    s=40,  # Smaller rhombus\n)\n\n# Add a legend for the averages\nplt.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', fontsize=10)\n\n# Save the plot\nplot_path = os.path.join(optimization_dir, \"environmental-impact-across-methods-and-crops-with-averages.png\")\nplt.tight_layout()\nplt.savefig(plot_path, dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"papermill":{"duration":0.95167,"end_time":"2025-02-14T07:48:04.364336","exception":false,"start_time":"2025-02-14T07:48:03.412666","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"1208e6bc","cell_type":"code","source":"def _grid_mask_smooth(x, y, z, nx=150, ny=150, smooth_frac=0.3, gauss_sigma=0.8, rbf_func='thin_plate'):\n    \"\"\"Interpolate with RBF, mask outside convex hull, lightly smooth.\"\"\"\n    gx = np.linspace(x.min(), x.max(), nx)\n    gy = np.linspace(y.min(), y.max(), ny)\n    GX, GY = np.meshgrid(gx, gy)\n\n    rbf = Rbf(x, y, z, function=rbf_func, smooth=z.std() * smooth_frac if np.std(z) > 0 else 1e-6)\n    GZ = rbf(GX, GY)\n\n    hull = Delaunay(np.c_[x, y])\n    outside = hull.find_simplex(np.c_[GX.ravel(), GY.ravel()]) < 0\n    GZ = GZ.astype(float)\n    GZ.ravel()[outside] = np.nan\n\n    if gauss_sigma and gauss_sigma > 0:\n        GZ = gaussian_filter(GZ, sigma=gauss_sigma)\n    return GX, GY, GZ\n\ndef _panel_norm(GZ, mode='sequential', vcenter=0.0, q=(2, 98)):\n    \"\"\"Per-panel robust normalization from gridded values.\"\"\"\n    v = GZ[~np.isnan(GZ)]\n    if v.size == 0:\n        # fallback to something sane\n        return Normalize(vmin=0, vmax=1)\n    vmin, vmax = np.percentile(v, q)\n    if mode == 'diverging':\n        return TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n    return Normalize(vmin=vmin, vmax=vmax)\n\ndef plot_npk_objective_surfaces_paper(crop_data, crop,\n                                      cmap='viridis',\n                                      mode='sequential',  # 'sequential' or 'diverging'\n                                      vcenter=0.0,\n                                      save_dir='optimization'):\n    # Inputs\n    N = crop_data['Optimized N'].to_numpy()\n    P = crop_data['Optimized P'].to_numpy()\n    K = crop_data['Optimized K'].to_numpy()\n    Z = crop_data['Objective Value'].to_numpy()\n\n    # Build three surfaces\n    GX_np, GY_np, GZ_np = _grid_mask_smooth(N, P, Z)\n    GX_nk, GY_nk, GZ_nk = _grid_mask_smooth(N, K, Z)\n    GX_pk, GY_pk, GZ_pk = _grid_mask_smooth(P, K, Z)\n\n    # Figure\n    fig = plt.figure(figsize=(18, 6))\n    plt.subplots_adjust(left=0.05, right=0.95, wspace=0.45)\n\n    # Helper to plot a single panel with its OWN norm\n    def _plot(ax, GX, GY, GZ, title, xl, yl):\n        norm = _panel_norm(GZ, mode=mode, vcenter=vcenter, q=(2, 98))\n        surf = ax.plot_surface(GX, GY, GZ,\n                               cmap=cmap, norm=norm,\n                               edgecolor='none', antialiased=True, shade=False,\n                               rstride=1, cstride=1, linewidth=0)\n        ax.set_title(title, fontsize=14)\n        ax.set_xlabel(xl, fontsize=12)\n        ax.set_ylabel(yl, fontsize=12)\n        ax.set_zlabel('Objective value', fontsize=12)\n        # Colorbar\n        cbar = fig.colorbar(surf, ax=ax, shrink=0.55, pad=0.10)\n        cbar.set_label('Objective value', fontsize=10)\n        cbar.locator = mticker.MaxNLocator(5)\n        cbar.formatter = mticker.ScalarFormatter(useMathText=True)\n        cbar.update_ticks()\n        # A consistent, readable view\n        ax.view_init(elev=28, azim=-55)\n\n    # Panels (each gets its own color scale)\n    ax1 = fig.add_subplot(131, projection='3d')\n    _plot(ax1, GX_np, GY_np, GZ_np, f'N-P Objective Surface for {crop}', 'N (kg/ha)', 'P (kg/ha)')\n\n    ax2 = fig.add_subplot(132, projection='3d')\n    _plot(ax2, GX_nk, GY_nk, GZ_nk, f'N-K Objective Surface for {crop}', 'N (kg/ha)', 'K (kg/ha)')\n\n    ax3 = fig.add_subplot(133, projection='3d')\n    _plot(ax3, GX_pk, GY_pk, GZ_pk, f'P-K Objective Surface for {crop}', 'P (kg/ha)', 'K (kg/ha)')\n\n    plt.tight_layout()\n    import os\n    os.makedirs(save_dir, exist_ok=True)\n    plt.savefig(f'{save_dir}/{crop}_3D_NPK_Objective_Surfaces_PERPANEL.png', dpi=240)\n    plt.show()\n\nfor crop in optimization_results_df['Crop'].unique():\n    crop_df = optimization_results_df[optimization_results_df['Crop'] == crop]\n    plot_npk_objective_surfaces_paper(crop_df, crop,\n                                      cmap='viridis',      # or 'cividis' (colorblind-safe)\n                                      mode='sequential',   # or 'diverging'\n                                      vcenter=0.0,\n                                      save_dir='optimization')","metadata":{"papermill":{"duration":5.516157,"end_time":"2025-02-14T07:48:09.988450","exception":false,"start_time":"2025-02-14T07:48:04.472293","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}